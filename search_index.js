var documenterSearchIndex = {"docs":
[{"location":"tutorials/installation/#Installing-Julia-Environment","page":"Installing Julia","title":"Installing Julia Environment","text":"","category":"section"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"It takes less than one minute to setup Julia environment on any machine, So I'm sharing few other possible installation methods to setup your local machine, remote VMs or mobile devices for Julia computing.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Please chose any of the below methods depending on your available resources you would like to setup Julia environment for General Ledger data analysis.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"iPad is next computer and (Image: Julia Language) is next big thing in high speed parallel, distributed & asynchronous numerical computing. ","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"In this blog, I'm sharing, how I setup my iPad as primary developer machine to run heavy data science numerical computing over cloud VMs.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"how to install & access Julia, Jupyter, Pluto, VSCode on local & Cloud VMs.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"These hacks are for people like me, who wake up middle of night and expect a Julia notebook ready in less than 10 seconds on their mobile device.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Topics","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"how to install Julia on local windows, mac, linux\nhow to install Julia on Cloud Windows VM\nhow to install Julia on Cloud Linux VM\nrun Julia REPL on Cloud Windows, Linux VMs through SSH client\nrun Pluto or Jupyter notebooks on VM servers and access from remote Browser, iPad or Android tablets\nuse GitHub to sync your work\nrun VS Code on iPad/Tablet devices\nUnderstanding Julia Project, Application, Environment, Package","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"","category":"page"},{"location":"tutorials/installation/#on-local-windows,-mac,-linux","page":"Installing Julia","title":"on local windows, mac, linux","text":"","category":"section"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"it takes less than one minute to install and start with Julia.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"click here to download Julia Language binaries","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Extract zip file contents to any folder on your local machine and change Windows/Mac/Linux environment variables/system Path to find Julia.exe on this folder.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"for example","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Windows","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"$env:PATH\r\nC:\\amit\\julia-1.5.2\\bin","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Linux/mac","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"export PATH=$PATH:/place/with/the/julia-1.5.2/bin","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"(Image: Windows environment variable)","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"now open a terminal window and type","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"julia","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"if all is well, you should have a working Julia session as shown below","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"(Image: Julia Terminal window)","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"","category":"page"},{"location":"tutorials/installation/#on-Cloud-Windows-VM","page":"Installing Julia","title":"on Cloud Windows VM","text":"","category":"section"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Before you begin","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Make sure that billing is enabled for your Google Cloud Platform project. open Google Cloud.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"browse to Compute Engine -> VM Instances -> New VM Instance","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Let's spin a moderate size windows compute Optimized VM in Google cloud","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"(Image: Google cloud Windows VM)","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Once Google VM is installed, please start the machine and setup windows password","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"(Image: Google cloud Windows VM)","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Connecting from local windows machine to this Cloud Windows VM","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"(Image: Google cloud Windows VM)","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Use your iPAD to connect to Google Cloud Windows VM","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"(Image: Google cloud Windows VM)","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Once your windows server is up and running, follow Section #1 (see above) for Julia Lang installation.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Don't forget to STOP your windows VM when you finish.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"(Image: Google cloud Windows VM)","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"","category":"page"},{"location":"tutorials/installation/#on-Cloud-Linux-VM","page":"Installing Julia","title":"on Cloud Linux VM","text":"","category":"section"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Before you begin Make sure that billing is enabled for your Google Cloud Platform project. open Google Cloud.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"browse to Compute Engine -> VM Instances -> New VM Instance","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Let's spin a moderate size Linux compute Optimized VM in Google cloud","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"(Image: Google cloud Windows VM)","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"If you want a complete Linux desktop experience, please follow this blog.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Detail instuctions - How to Install Debian 10 (Buster) or Ubuntu 18/19 Desktop on Google Cloud and access through VNC","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Once your Linux VM server is up and running, follow Section #1 (see above) for Julia Lang installation.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"","category":"page"},{"location":"tutorials/installation/#run-Julia-REPL-on-Cloud-Windows,-Linux-VMs-through-SSH-client","page":"Installing Julia","title":"run Julia REPL on Cloud Windows, Linux VMs through SSH client","text":"","category":"section"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"download Julia binaries and setup system PATH as discussed in Section #1 above.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Linux/mac export PATH=PATH:/place/with/the/julia-1.5.2/bin","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"On Windows cloud VM, this is simple setup, open PORT:1234 for remote access.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"On Linux cloud VM, User will need set up an SSH tunnel.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"local computer - download putty\nGoogle Cloud- open Google Cloud. click on SSH, this will open a SSH inside browser pop-up window.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"First, log in to your server using SSH and start a Pluto server. Then open a local terminal on your own computer and type:","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"ssh userid@vmipaddress -LN 1234:localhost:1234","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"","category":"page"},{"location":"tutorials/installation/#run-Jupyter-and-Pluto-notebook-through-remote-browser","page":"Installing Julia","title":"run Jupyter & Pluto notebook through remote browser","text":"","category":"section"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"You can run Jupyter notebook or Pluto on a Windows/Linux VM and use the browser on your own computer or mobile device as user interface.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"I'll split this section in two part, Jupyter and Pluto, let's get started with Jupyter first.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"5a. How to run & access Jupyter notebook through remote browser","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"5b. How to run & access Pluto notebook through remote browser","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"SSH Tunnel create a pathway to access your remote cloud VM server","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"(Image: SSH diagram)","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"","category":"page"},{"location":"tutorials/installation/#a.-How-to-run-and-access-Jupyter-notebook-through-remote-browser","page":"Installing Julia","title":"5a. How to run & access Jupyter notebook through remote browser","text":"","category":"section"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"on your server, first start Jupyter environment using this command","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Julia > Using Pkg; \r\n        Pkg.add(\"IJulia\");\r\n        using IJulia;\r\n        installkernel(\"Julia (4 threads)\", env=Dict(\"JULIA_NUM_THREADS\"=>\"4\"))\r\n            # JULIA_NUM_THREADS should be cores available as per your machine\r\n        jupyterlab();\r\nor\r\n\r\njupyter notebook --no-browser --port 1234\r\n\r\n# above command will start a notebook server with URL like http://localhost:8888/?token=abc123........","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Access Jupyter notebook on Linux cloud VM","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"on your SSH window, type one of following commands","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"ssh -L 1234:localhost:1234 username@xxx.xx.xx.xx\r\nssh -L 1234:localhost:1234 -i /path/to/private_key","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Access Jupyter notebook on Windows cloud VM","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"download and setup putty like this","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"(Image: setup putty to access windows vm)","category":"page"},{"location":"tutorials/installation/#b.-How-to-run-and-access-Pluto-notebook-through-remote-browser","page":"Installing Julia","title":"5b. How to run & access Pluto notebook through remote browser","text":"","category":"section"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"on your server, type following commands","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Julia > Using Pkg; \r\n        Pkg.add(\"Pluto\")\r\n        Pluto.CONFIG[\"PLUTO_RUN_NOTEBOOK_ON_LOAD\"] = \"false\" Pluto.ENV_DEFAULTS[\"PLUTO_RUN_NOTEBOOK_ON_LOAD\"] = \"false\"\r\n            # above command is optional and prevent notebook to auto-run on load\r\n        Pluto.run(; launch_browser: \"false\", host: \"0.0.0.0\", port: 1234)\r\n        \r\n# above commands will start Pluto on http://[cloudvmipaddress]:[port]/\r\n\r\nor\r\n        \r\n# alternate, like Jupyter, you can always access your Pluto notebook through SSH terminal as well\r\nssh user@ipaddress -LN 1234:localhost:1234","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"","category":"page"},{"location":"tutorials/installation/#use-GitHub-to-sync-your-work","page":"Installing Julia","title":"use GitHub to sync your work","text":"","category":"section"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"This section is just to remind you that using GitHub repositories saves you tons of re-work. You can setup projects and sync your code across devices among teams.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Please check out this video playlist if you are new to GitHub to learn more.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"GitHub Video Tutorials","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"","category":"page"},{"location":"tutorials/installation/#run-VS-Code-on-iPad/Tablet-devices-using-coder-server","page":"Installing Julia","title":"run VS Code on iPad/Tablet devices using coder-server","text":"","category":"section"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Step 1: You should already have a cloud Linux VM. (see Section #3 above)\nStep 2: login into your cloud VM through SSH (see Section #4 above)\nStep 3: type below commands one by one in SSH window","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"wget https://github.com/cdr/code-server/releases/download/v3.7.1/code-server-3.7.1-linux-arm64.tar.gz\r\n    # above command will download latest copy of code-server binaries, \r\n    # https://github.com/cdr/code-server/releases. change the binaries version to latest available release as per your machine configuration\r\ntar -xvf ./code-server-3.7.1-linux-arm64.tar.gz coder\r\n    # above command will unzip code binaries\r\ncd coder\r\n    # change directory to coder folder\r\nchmod +x ./coder\r\n    # change executable permission on this folder\r\nsudo ufw allow 80/tcp\r\n    # allow http access on port 80 to this folder\r\n./coder -p 80 --allow-http\r\n    # note down password","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"open any browser window on your mobile/computer and access this URL","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"http://yourcloudvmipaddress/","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"you should now have vscode running on your browser window.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"","category":"page"},{"location":"tutorials/installation/#Understanding-Julia-Project,-Application,-Environment,-Package","page":"Installing Julia","title":"Understanding Julia Project, Application, Environment, Package","text":"","category":"section"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Each of these terms above describes what are you trying to achieve.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"A Julia language Project is literally a project, reflects your objective you are trying to accomplish in your project. Like any other software project, your project has source code files typically placed under src directory, documentation under docs and test cases kept in test directory.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Application is a kind of project trying to achieve a specific goal, for example, a micro services or web app or Research analysis or white paper. Applications unlike Package & Environment don't need UUID. It can be a simple notebook or Julia file. Applications can provide global configuration, whereas packages cannot.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Environment is a Julia Lang environment, which completely describes all packages and related dependency. Julia environment typically keep required packages (specific UUID  universal unique identifier) in project.toml and manifesto.toml complete dependency graph of packages.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Environments are helpful to complete re-produce a work environment in any other developer machine.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Package is typically like a Julia Environment with a clear motive, that this package provide re-usable functionalities that can be used in other Julia language development environments/projects.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"Modules are individual components of your overall Julia package which implement a discrete functionality.","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"learn more - ","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"https://julialang.github.io/Pkg.jl/dev/glossary/","category":"page"},{"location":"tutorials/installation/","page":"Installing Julia","title":"Installing Julia","text":"https://julialang.github.io/Pkg.jl/dev/getting-started/","category":"page"},{"location":"tutorials/nlp/#Natural-Language-Processing-for-General-Ledger","page":"NLP for GL","title":"Natural Language Processing for General Ledger","text":"","category":"section"},{"location":"tutorials/nlp/","page":"NLP for GL","title":"NLP for GL","text":"Dynamic roll ups","category":"page"},{"location":"tutorials/nlp/","page":"NLP for GL","title":"NLP for GL","text":"Invoices by Diversity Vendor groups","category":"page"},{"location":"tutorials/nlp/","page":"NLP for GL","title":"NLP for GL","text":"Vendor Ranking","category":"page"},{"location":"tutorials/nlp/","page":"NLP for GL","title":"NLP for GL","text":"Product Ranking","category":"page"},{"location":"tutorials/nlp/","page":"NLP for GL","title":"NLP for GL","text":"Cost per Invoice","category":"page"},{"location":"tutorials/nlp/","page":"NLP for GL","title":"NLP for GL","text":"Operating Expenses trend","category":"page"},{"location":"tutorials/nlp/","page":"NLP for GL","title":"NLP for GL","text":"What if scenarios","category":"page"},{"location":"tutorials/nlp/","page":"NLP for GL","title":"NLP for GL","text":"Income, Cash-Flow & Balance sheet statements","category":"page"},{"location":"tutorials/nlp/","page":"NLP for GL","title":"NLP for GL","text":"Using JULIAGRAPHS for combinational data","category":"page"},{"location":"tutorials/nlp/","page":"NLP for GL","title":"NLP for GL","text":"Tree Flattener","category":"page"},{"location":"api/#Manual/API","page":"API","title":"Manual/API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Modules = [GeneralLedger]\r\nOrder   = [:function, :type]","category":"page"},{"location":"api/#GeneralLedger.getArrangedWords-Tuple{Any}","page":"API","title":"GeneralLedger.getArrangedWords","text":"getArrangedWords(str) Call this function to remove duplicates, unwanted symbols and return uppercase unique values\n\nExample\n\njulia> wd = getArrangedWords(\"Amit ; Shukla SHUKLA Shukle , . AmIT Amit # Shuklam Amit ,\")\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.getCategoryData-Tuple{Any, Any}","page":"API","title":"GeneralLedger.getCategoryData","text":"getCategoryData(df_dname:: DataFrame, colName:: AbstractString, categoryRange) Call this function to create a new column on DataFrame which provide a category based on ranges provided.\n\ncolumn must be contain only numerical values.\n\nFirst parameter is the DataFrame, next is Column name for which categories are created, followed by Ranges.\n\nFunction returns dataframe with an extra columns with Categories like 1,2,3 and 0 for unmatched.\n\nExample\n\njulia> df_dname = DataFrame(name=[\"John Doe\", \"John Doe\",\"MICHAEL Doe\", \"Jacob Doe\", \"Julia Dpe\", \"Michael Jackson\"],age=[35,35,35,10,5,45], state=[\"CA\",\"CA\",\"CA\",\"CA\",\"CO\",\"CA\"])\njulia> catData = getCategoryData(df_dname, \"age\", [0:10,10:20,20:30])\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.getDBConnection-Tuple{AbstractString}","page":"API","title":"GeneralLedger.getDBConnection","text":"getDBConnection(credFilePath:: AbstractString)\n\nCall this function to read database credentials\n\ndatabase credentials are stored in environment.txt file in following format.\n\nenvironment.txt\n\nuser=username\npwd=password\ndsn=userdsnname\nhive=hdinsightstr\nport=portnumber\n\nExample\n\njulia> fl = getDBConnection(\"environment.txt\")\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.getDSNs-Tuple{}","page":"API","title":"GeneralLedger.getDSNs","text":"getDSNs()\n\nCall this function to read computing machine available DSNs\n\nExample\n\njulia> dsns = getDSNs()\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.getDrivers-Tuple{}","page":"API","title":"GeneralLedger.getDrivers","text":"getDrivers()\n\nCall this function to read computing machine available Drivers\n\nExample\n\njulia> drivers = getDrivers()\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.getDuplicateRows-Tuple{Any, Any}","page":"API","title":"GeneralLedger.getDuplicateRows","text":"getDuplicateRows(df_dname:: DataFrame, colNames:: Vector) Call this function to find duplicates in a data frame column based on columnnames (key columns)\n\nFirst parameter is the DataFrame, followed by all columnnames in DataFrame which are key columns in a dataframe.\n\nFunction returns dataframe row indexes which are duplicates based on key columns provided.\n\nExample\n\njulia> df_dname = DataFrame(name=[\"John Doe\", \"John Doe\",\"MICHAEL Doe\", \"Jacob Doe\", \"Julia Dpe\", \"Michael Jackson\"],age=[35,35,35,10,5,45], state=[\"CA\",\"CA\",\"CA\",\"CA\",\"CO\",\"CA\"])\njulia> dup = getDuplicateRows(df_dname, [\"name\",\"age\"])\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.getFile-Tuple{AbstractString, AbstractString}","page":"API","title":"GeneralLedger.getFile","text":"getFile(url::AbstractString, downloadPath:: AbstractString)\n\nCall this function to download a file\n\nfirst parameter is webpage url, next parameter is output directory path including file name\n\nExample\n\njulia> fl = getFile(\"https://s2.q4cdn.com/470004039/files/doc_financials/2021/q2/FY21-Q2-Consolidated-Financial-Statements.pdf\", \"<folder_name>/test.csv\")\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.getFuzzyWuzzy-Tuple{Any, Any, Any}","page":"API","title":"GeneralLedger.getFuzzyWuzzy","text":"getFuzzyWuzzy(str) Call this function to find closest match for a given string in data frame column lookup\n\nFirst parameter is the search string, second is the DataFrame followed by columnname in DataFrame which needs to be searched\n\nExample\n\njulia> df_dname = DataFrame(name=[\"John Doe\", \"Jen Doe\",\"MICHAEL Doe\", \"Jacob Doe\", \"Julia Dpe\", \"Michael Jackson\"],age=[35,26,35,10,5,45])\njulia> wd = getFuzzyWuzzy(\"Mike Jackson\", df_dname, \"name\")\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.getJSONintoDataFrame-Tuple{AbstractString, AbstractString}","page":"API","title":"GeneralLedger.getJSONintoDataFrame","text":"getJSONintoDataFrame(path::AbstractString)\n\nCall this function to read json file from url and retrieve results into DataFrame\n\nfirst parameter is webpage url, next parameter is output directory path\n\nExample\n\njulia> df = getJSONintoDataFrame(\"https://api.coindesk.com/v1/bpi/currentprice.json\", \"downloads/web\")\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.getKeyColumns-Tuple{Any}","page":"API","title":"GeneralLedger.getKeyColumns","text":"getKeyColumns(df_dname:: DataFrame) Call this function to find key columns in a data frame\n\nFirst parameter is the DataFrame\n\nFunction returns dataframe columns indexes which are key columns.\n\nExample\n\njulia> df_dname = DataFrame(name=[\"John Doe\", \"John Doe\",\"MICHAEL Doe\", \"Jacob Doe\", \"Julia Dpe\", \"Michael Jackson\"],age=[35,35,35,10,5,45], state=[\"CA\",\"CA\",\"CA\",\"CA\",\"CO\",\"CA\"])\njulia> kcols = getKeyColumns(df_dname)\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.getMaskedData-Tuple{Any, Any}","page":"API","title":"GeneralLedger.getMaskedData","text":"getMaskedData(df_dname:: DataFrame, colNames:: Vector) Call this function to create a flatten tree data structure.\n\nFirst parameter is the DataFrame, next is Column names which needs to be masked\n\nFunction returns a two dataframes, one with masked data and other with masked + original data.\n\nExample\n\njulia> df_dname = DataFrame(name=[\"John Doe\", \"John Doe\",\"MICHAEL Doe\", \"Jacob Doe\", \"Julia Dpe\", \"Michael Jackson\"],age=[35,35,35,10,5,45], state=[\"CA\",\"CA\",\"CA\",\"CA\",\"CO\",\"CA\"])\njulia> catData = getMaskedData(df_dname, \"name\")\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.getPullFiles-Tuple{AbstractString}","page":"API","title":"GeneralLedger.getPullFiles","text":"getPullFiles(path::AbstractString)\n\nCall this function to read urls in local txt files line by line, and download each file\n\nExample\n\njulia> fl = getPullFiles(\"c:\u0007mit.la\filename.txt\")\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.getSQLs-Tuple{AbstractString}","page":"API","title":"GeneralLedger.getSQLs","text":"getSQLs(credFilePath:: AbstractString)\n\nCall this function to read sqls for a given table from txt file. SQLs are stored in txt file in this format.\n\nsqls.txt\n\ncreateTable1=INSERT INTO table1 (column1) SELECT table2.column1 FROM table2 WHERE table2.column1 > 100;\nreadTable1=SELECT * FROM table1;\nupdateTable1=UPDATE table SET column1 = value1, column2 = value2, ... WHERE condition;\nupsertTable1=BEDIN tran IF EXISTS (SELECT * FROM table1 WITH (updlock,serializable) WHERE key = @key) BEGIN UDPATE table1 SET ... WHERE key = @key END ELSE BEGIN INSERT INTO table1 (key, ...) VALUES (@key, ...) END COMMIT TRAN\nsoftDeleteTable1=UPDATE table SET deleted=True, ... WHERE condition;\nhardDeleteTable1=delete * from table1 where table1.column1 > 100\n\nExample\n\njulia> fl = getSQLs(\"environment.txt\")\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.getTokens-Tuple{Any, Any}","page":"API","title":"GeneralLedger.getTokens","text":"getTokens(s, token_type) Call this function to extract tokens from string (example - extract urls)\n\nFirst parameter is the complete string text, next parameter is list of words to be removed.\n\nExample\n\njulia> wd = getTokens(\"https://yahoo.com is the Yahoo website url\", url)\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.getTreeData-Tuple{Any, Any}","page":"API","title":"GeneralLedger.getTreeData","text":"getTreeData(df_dname:: DataFrame, colName:: AbstractString) Call this function to create a flatten tree data structure.\n\nFirst parameter is the DataFrame, next is Column name for which tree hierachies (flattened) are created.\n\nFunction returns a new dataframe with Levels.\n\nExample\n\njulia> df_dname = DataFrame(name=[\"John Doe\", \"John Doe\",\"MICHAEL Doe\", \"Jacob Doe\", \"Julia Dpe\", \"Michael Jackson\"],age=[35,35,35,10,5,45], state=[\"CA\",\"CA\",\"CA\",\"CA\",\"CO\",\"CA\"])\njulia> catData = getTreeData(df_dname, \"state\")\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.getWebLinks-Tuple{AbstractString, AbstractVector{T} where T, AbstractString}","page":"API","title":"GeneralLedger.getWebLinks","text":"getWebLinks(url::AbstractString, fileTypes::AbstractVector, downloadPath:: AbstractString)\n\nCall this function to crawl through a web page and download all file links\n\nfirst parameter is webpage url, next parameter is list of all file extensions user wish to download followed by output directory path\n\nExample\n\njulia> fl = getWebLinks(\"https://investor.apple.com/investor-relations/default.aspx#tabs_content--2021\", [\"pdf\",\"csv\",\"xlsx\",\"xls\"], \"downloads/web\")\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.getXLSinDirectory-Tuple{Any}","page":"API","title":"GeneralLedger.getXLSinDirectory","text":"getXLSinDirectory(str)\n\nCall this function to read all xls files inside directory\n\nExample\n\njulia> files = getXLSinDirectory(\"dirname\")\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.getXMLintoDataFrame-Tuple{AbstractString, AbstractString}","page":"API","title":"GeneralLedger.getXMLintoDataFrame","text":"getXMLintoDataFrame(path::AbstractString)\n\nCall this function to read XML file from url and retrieve results into DataFrame\n\nfirst parameter is webpage url, next parameter is output directory path\n\nExample\n\njulia> df = getXMLintoDataFrame(\"https://api.coindesk.com/v1/bpi/currentprice.json\", \"downloads/web\")\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.runSQL-Tuple{AbstractString, AbstractString}","page":"API","title":"GeneralLedger.runSQL","text":"runSQL(conn:: AbstractString, sql:: AbstractString)\n\nCall this function to run sql in database\n\nExample\n\njulia> res = runSQL(conn, SQLStatement)\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.setCloseConnection-Tuple{}","page":"API","title":"GeneralLedger.setCloseConnection","text":"setCloseConnection()\n\nCall this function to close database connection\n\nExample\n\njulia> cls = setCloseConnection()\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.setColNames-Tuple{Any}","page":"API","title":"GeneralLedger.setColNames","text":"setColNames(str)\n\nCall this function to update column names\n\nremove blank spaces, dollar sign, or Hash chars\n\nmake all columns uppercase and replace hyphen with underscore\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.setRemDuplicateRows-Tuple{Any, Any}","page":"API","title":"GeneralLedger.setRemDuplicateRows","text":"setRemDuplicateRows(df_dname:: DataFrame, colNames:: Vector) Call this function to find & delete duplicates in a data frame column based on columnnames (key columns)\n\nFirst parameter is the DataFrame, followed by all columnnames in DataFrame which are key columns in a dataframe.\n\nFunction returns dataframe after removing duplicates based on key columns provided. in case of duplicates, it retains first row.\n\nExample\n\njulia> df_dname = DataFrame(name=[\"John Doe\", \"John Doe\",\"MICHAEL Doe\", \"Jacob Doe\", \"Julia Dpe\", \"Michael Jackson\"],age=[35,35,35,10,5,45], state=[\"CA\",\"CA\",\"CA\",\"CA\",\"CO\",\"CA\"])\njulia> dup = setRemDuplicateRows(df_dname, [\"name\",\"age\"])\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.setRemoveText-Tuple{Any, Any}","page":"API","title":"GeneralLedger.setRemoveText","text":"setRemoveText(str) Call this function to find and remove word in text string\n\nFirst parameter is the complete string text, next parameter is list of words to be removed.\n\nExample\n\njulia> wd = setRemoveText(\"Amit Shukla Shkla Los Angel Angeles\", [\"Shkla\", \"Angel\"])\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.setRemoveTokens-Tuple{Any}","page":"API","title":"GeneralLedger.setRemoveTokens","text":"setRemoveTokens(str) Call this function to remove tokens\n\nExample\n\njulia> wd = setRemoveTokens(\"Amit Shukla Shkla Los Angel Angeles\")\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.setReplaceText-Tuple{Any, Any, Any}","page":"API","title":"GeneralLedger.setReplaceText","text":"setReplaceText(str) Call this function to find and replace word in text string\n\nFirst parameter is the term to be replaced, next is the term replaced with followed by text string where text is searched and replaced.\n\nExample\n\njulia> wd = setReplaceText(\"Shkla\",\"Shukla \",\"Amit Shkla Los Angeles\")\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.SubRecordINSMetadata-Tuple{}","page":"API","title":"GeneralLedger.SubRecordINSMetadata","text":"SubRecordINSMetadata(source::String, createDTTM::String, updateDTTM::String, author::String)\n\nStores metadata about records/document loaded into data lake. ...\n\nArguments\n\nsource::String: stores SOR (system of record i.e. source) name\ncreateDTTM::String : data & time when data was first loaded.\nupdateDTTM::String : data & time when data was last updated (equals to createDTTM in case of no updates).\nauthor::String : name of the person responsible for loading data.\n\n...\n\n\n\n\n\n","category":"method"},{"location":"api/#GeneralLedger.SubRecordUPDMetadata-Tuple{}","page":"API","title":"GeneralLedger.SubRecordUPDMetadata","text":"SubRecordUPDMetadata(source::String, updateDTTM::String, author::String)\n\nStores metadata about records/document loaded into data lake. ...\n\nArguments\n\nsource::String: stores SOR (system of record i.e. source) name\nupdateDTTM::String : data & time when data was last updated (equals to createDTTM in case of no updates).\nauthor::String : name of the person responsible for loading data.\n\n...\n\n\n\n\n\n","category":"method"},{"location":"tutorials/data_load/","page":"-","title":"-","text":"Data Loading ############","category":"page"},{"location":"tutorials/data_load/","page":"-","title":"-","text":"Objective ^^^^^^^^^ In this section, We will discuss, different ways to read, store different kinds of Data.","category":"page"},{"location":"tutorials/data_load/","page":"-","title":"-","text":"In real world, most of Big/small Organizations use ERP Systems like SAP, Oracle, PeopleSoft, Intuit, MS SQL/Access/SQL Server etc. to store Summary, Detail & Sub Ledgers in ERP systems. These ERP systems store Giga/Peta Bytes of GL data in RDBMS tables and mostly in highly structured data format.","category":"page"},{"location":"tutorials/data_load/","page":"-","title":"-","text":"using Python ^^^^^^^^^^^^","category":"page"},{"location":"tutorials/data_load/","page":"-","title":"-","text":"NumPy, Pandas DataFrame is one of the recommended way to load and read CSV, XLSX or Website data.\nVAEX, PyTables or PYSPARK are few other recommended approaches to store high volume, highly structured data.","category":"page"},{"location":"tutorials/data_load/","page":"-","title":"-","text":"using Julia ^^^^^^^^^^^","category":"page"},{"location":"tutorials/data_load/","page":"-","title":"-","text":"Julia DataFrame is one of the recommended way to load and read CSV, XLSX or Website data.\nJuliaDB is other approach recommended to store high volume, highly structured data.","category":"page"},{"location":"tutorials/data_load/","page":"-","title":"-","text":"using CSV ^^^^^^^^^ .. content-tabs::","category":"page"},{"location":"tutorials/data_load/","page":"-","title":"-","text":".. tab-container:: Python\r\n    :title: Python\r\n\n    .. code-block:: Python\r\n        :linenos:\r\n\n        import numpy as np\r\n        import pandas as pd\r\n        df = DataFrame(a=3, b=5)\r\n        df.a\r\n        df[:,:a]\r\n\n.. tab-container:: Julia\r\n    :title: Julia\r\n\n    .. code-block:: Julia\r\n        :linenos:\r\n\n        using Pkg           # load Pkg\r\n        Pkg.add(\"CSV\")      # add CSV package\r\n        using CSV           # load CSV\r\n        df = CSV.           # hit TAB to see all available methods\r\n        \r\n        # before you jump on loading CSV file, always count rows in CSV.\r\n\n        (open(\"./Ledger.csv\") |> readlines |> length) -1 # use readlines if file is clean format\r\n        \r\n        function rowcountcsv(file)    # write a generic funciton to readlines in a file (not so clean files)\r\n            rowCount = 0\r\n            for row in CSV.Rows(file; resusebuffer=true)\r\n                rowCount += 1\r\n            end\r\n            return rowCount\r\n        end\r\n        \r\n        rowcountcsv(\"./Ledger.csv\") # count # of lines in CSV\r\n\n        # OMG, you don't want to print 100,000 lines from a big CSV file, but if you do...\r\n        for row in CSV.File(\"./Ledger.csv\")\r\n            println(\"a=$(row.a), b=$(row.b), c=$(row.c)\")\r\n        end\r\n\n        #### APPROACH - 1 ####\r\n        #### let's load this CSV into a DataFrame ####\r\n        using DataFrames\r\n        df = CSV.File(\"./Ledger.csv\") |> DataFrame!\r\n\n        #### APPROACH - 2 ####\r\n        # load a csv file directly into an sqlite database table\r\n        using Pkg\r\n        Pkg.add(\"SQLite\")\r\n        db = SQLite.DB()\r\n        tbl = CSV.File(\"./Ledger.csv\") |> SQLite.load!(db, \"ledger_table\")\r\n\n        #### APPROACH - 3 ####\r\n        #### loading data into JuliaDB ####\r\n        using Pkg\r\n        Pkg.add(\"JuliaDB\")\r\n        Pkg.add(\"Distributed\")\r\n        Pkg.add(\"OnlineStats\")\r\n\n        using JuliaDB\r\n        using Distributed\r\n        using OnlineStats\r\n        addprocs(4)\r\n\n        @everywhere using JuliaDB, OnlineStats\r\n        files = glob(\"*.csv\", \"Ledger\") # load all csvs at once in directory\r\n\n        t = loadtable(files, filenamecol=:DBLedger) #DBLedger becomes one of column in this table\r\n        groupreduce(Mean(), t, :DBLedger; select=:BALANCE) # assuming Ledger.csv has a column BALANCE","category":"page"},{"location":"tutorials/data_load/","page":"-","title":"-","text":"using DOWNLOAD ^^^^^^^^^^^^^^","category":"page"},{"location":"tutorials/data_load/","page":"-","title":"-","text":"using XLSX ^^^^^^^^^^","category":"page"},{"location":"tutorials/data_load/","page":"-","title":"-","text":"using ODBC ^^^^^^^^^^","category":"page"},{"location":"tutorials/data_load/","page":"-","title":"-","text":"using JDBC ^^^^^^^^^^","category":"page"},{"location":"tutorials/data_load/","page":"-","title":"-","text":"using HIVE ^^^^^^^^^^","category":"page"},{"location":"tutorials/data_load/","page":"-","title":"-","text":"using Website ^^^^^^^^^^^^^","category":"page"},{"location":"tutorials/glprocesses/#GL-Processes","page":"GL Processes","title":"GL Processes","text":"","category":"section"},{"location":"tutorials/glprocesses/","page":"GL Processes","title":"GL Processes","text":"Typical General Ledgers processes integrate with other business processes and accepts accounting entries through pre-defined journal entry templates.","category":"page"},{"location":"tutorials/glprocesses/","page":"GL Processes","title":"GL Processes","text":"This journals lines further create summarized Ledger accounting entries Journals are created manually, uploaded using Excel, ETLs or sometime auto created, like allocations entries.","category":"page"},{"location":"tutorials/glprocesses/","page":"GL Processes","title":"GL Processes","text":"Journals and Accounting Entries are often not required for Financial Reports, however, these accounting entries are critical for analytics, detail analysis and provide a detail drill down for enhance GL analytics. GIven these accounting entries, its possible to predict Organization Finance growth with more accuracy.","category":"page"},{"location":"tutorials/glprocesses/","page":"GL Processes","title":"GL Processes","text":"There are so many different GL processes and lot of these processes depend on how organization manage their finance and accounting department, Purpose of this package is focused on read, understand data, rather how data is written into system, which is mostly handled by ERP systems.","category":"page"},{"location":"tutorials/glprocesses/","page":"GL Processes","title":"GL Processes","text":"(Image: ERP Modules)","category":"page"},{"location":"tutorials/glprocesses/","page":"GL Processes","title":"GL Processes","text":"(Image: GL Processes)","category":"page"},{"location":"tutorials/selfservice/#Self-Service-Analytics","page":"Self-Service Data Analytic","title":"Self Service Analytics","text":"","category":"section"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"In the previous chapter, we learned how to extract, load and transform data. Often, ERP system use RDBMS database to store data in normalized forms. However, recently, due to advancements in cloud computing, ELT Data lakes gained popularity to perform data analysis, high performance parallel computing in cloud environments.","category":"page"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"In this chapter, we will learn how to create self-service normalized data for ad-hoc reporting using The Julia Language. We will create sample data to mimic actuals datasets and will further create basic GL reports using this data.","category":"page"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"This tpye of drag 'n' drop ad-hoc analytics reporting is very popular using BI tools like Microsoft Power BI, Tableau, Kibana, OACs, Cognos etc.","category":"page"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"Creating these basic reports in Julia language may not look very useful in the beginning. This exercise should be seen as creating fundamental environment for reporting, which helps perform Advance Analytics, Real time analytics, Advance Visualizations and Predictive analytics on Financial data later on.","category":"page"},{"location":"tutorials/selfservice/#About-ERP-Systems,-General-Ledger-and-Supply-chain","page":"Self-Service Data Analytic","title":"About ERP Systems, General Ledger & Supply chain","text":"","category":"section"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"A typical ERP system consists of many modules based on business domain, functions and operations.","category":"page"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"GL is core of Finance and Supply chain domains and Buy to Pay, Order to Cash deal with different aspects of business operations in an Organization. Many organization, use ERPs in different ways and may chose to implement all or some of the modules.","category":"page"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"You can find examples of module specific business operations/processes diagram here.","category":"page"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"General Ledger process flow\nAccount Payable process flow\nTax Analytics\nSample GL ERD - Entity Relaton Diagram","category":"page"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"A typical ERP modules list looks like below diagram.","category":"page"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"(Image: ERP Modules)","category":"page"},{"location":"tutorials/selfservice/#Current-Solutions","page":"Self-Service Data Analytic","title":"Current Solutions","text":"","category":"section"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"Big Organizations have been using big ERP systems like SAP, Oracle, PeopleSoft, Coupa, Workday etc. systems over few decades now and  Recent popularity of softwares like Quickbooks, NetSuite, Tally in medium, small organizations are proof that ERP are the way to manage any business successfully.","category":"page"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"Finance analysts, supply chain managers heavily rely on using Business Intelligence tools like Microsoft Excel, Microsoft Power BI, Tableau, Oracle Analytics, Google Analytics, IBM Cognos, Business Objects etc. ","category":"page"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"These BI tools provide a self-service reporting for analytics and often are used for managing daily ad-hoc reporting and anlysis.","category":"page"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"A typical ERP data flow process looks like below diagram.","category":"page"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"(Image: GL Processes)","category":"page"},{"location":"tutorials/selfservice/#Problem-Statement","page":"Self-Service Data Analytic","title":"Problem Statement","text":"","category":"section"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"\"Read, Write and Understand\" data are three aspects of any ERP system.","category":"page"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"While big and small ERPs master \"write aspect\" of ERP, there is lot needs to be done on \"read & understand\" data.","category":"page"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"I would rather not waste your time talking about how one BI Tools compare with Pluto  or others, ","category":"page"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"instead, in this chapter, I will show some sample reports I built in Pluto last year for Pandemic reporting, and then let Analysts decide, if They would have rather used Traditional BI reportings tools to build these reports.","category":"page"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"Point is, How easily, Pluto can create real time ad-hoc, Reactive dashboard analytics to support critical business operations.","category":"page"},{"location":"tutorials/selfservice/#understanding-Finance,-Supply-chain-data","page":"Self-Service Data Analytic","title":"understanding Finance, Supply chain data","text":"","category":"section"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"A typical Finance statement look like this. click here","category":"page"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"Let's first create chartfields to support General Ledger finance books accounting structure, this accounting structure will support Ledger Analytics and should be interpreted as data structure responsilbe to create Finance Statements.","category":"page"},{"location":"tutorials/selfservice/#Examples","page":"Self-Service Data Analytic","title":"Examples","text":"","category":"section"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"below are sample data sets,","category":"page"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"Accounts, Dept (or Cost Center), Location, and Finance Ledger may look like below examples.","category":"page"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"Let's first activate GeneralLedger.jl package.","category":"page"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"# Let's first import GeneralLedger.jl package\r\n# in following examples, I'll assume, that you downloaded this package\r\nusing Pkg\r\nPkg.add(url=\"https://github.com/AmitXShukla/GeneralLedger.jl\")\r\nusing GeneralLedger","category":"page"},{"location":"tutorials/selfservice/#Accounts-Dimension","page":"Self-Service Data Analytic","title":"Accounts Dimension","text":"","category":"section"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"using DataFrames, Dates\r\n# create dummy data\r\naccounts = DataFrame(AS_OF_DATE=Date(\"1900-01-01\", dateformat\"y-m-d\"), \r\n\t\t\t\t\tID = 11000:1000:45000,\r\n\t\t\t\t\tCLASSIFICATION=repeat([\r\n\t\t\"OPERATING_EXPENSES\",\"NON-OPERATING_EXPENSES\", \"ASSETS\",\"LIABILITIES\",\r\n\t\t\"NET_WORTH\",\"STATISTICS\",\"REVENUE\"\r\n\t\t], inner=5),\r\n\tCATEGORY=[\r\n\t\t\"Travel\",\"Payroll\",\"non-Payroll\",\"Allowance\",\"Cash\",\r\n\t\t\"Facility\",\"Supply\",\"Services\",\"Investment\",\"Misc.\",\r\n\t\t\"Depreciation\",\"Gain\",\"Service\",\"Retired\",\"Fault.\",\r\n\t\t\"Receipt\",\"Accrual\",\"Return\",\"Credit\",\"ROI\",\r\n\t\t\"Cash\",\"Funds\",\"Invest\",\"Transfer\",\"Roll-over\",\r\n\t\t\"FTE\",\"Members\",\"Non_Members\",\"Temp\",\"Contractors\",\r\n\t\t\"Sales\",\"Merchant\",\"Service\",\"Consulting\",\"Subscriptions\"\r\n\t],\r\n\tSTATUS=\"A\",\r\n\tDESCR=repeat([\r\n\t\t\"operating expenses\",\"non-operating expenses\",\r\n\t\t\"assets\",\"liability\",\"net-worth\",\"stats\",\"revenue\"\r\n\t], inner=5),\r\n\tACCOUNT_TYPE=repeat([\r\n\t\"E\",\"E\",\"A\",\"L\",\"N\",\"S\",\"R\"\r\n\t\t\t\t],inner=5));\r\naccounts[collect(1:5:35),:]","category":"page"},{"location":"tutorials/selfservice/#Department-Dimension","page":"Self-Service Data Analytic","title":"Department Dimension","text":"","category":"section"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"using DataFrames, Dates\r\n# create dummy data\r\ndept = DataFrame(AS_OF_DATE=Date(\"2000-01-01\", dateformat\"y-m-d\"), \r\n\t\t\t\t\t\t\tID = 1100:100:1500,\r\n\t\t\t\t\t\t\tCLASSIFICATION=[\r\n\t\"SALES\",\"HR\", \"IT\",\"BUSINESS\",\"OTHERS\"\r\n\t],\r\n\t\t\t\t\t\t\tCATEGORY=[\r\n\t\"sales\",\"human_resource\",\"IT_Staff\",\"business\",\"others\"\r\n\t],\r\n\t\t\t\t\t\t\tSTATUS=\"A\",\r\n\t\t\t\t\t\t\tDESCR=[\r\n\t\"Sales & Marketing\",\"Human Resource\",\"Infomration Technology\",\"Business leaders\",\"other temp\"\r\n\t],\r\n\t\t\t\t\t\t\tDEPT_TYPE=[\r\n\t\"S\",\"H\",\"I\",\"B\",\"O\"]);\r\ndept[collect(1:5),:]","category":"page"},{"location":"tutorials/selfservice/#Location-Dimension","page":"Self-Service Data Analytic","title":"Location Dimension","text":"","category":"section"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"using DataFrames, Dates\r\n# create dummy data\r\nlocation = DataFrame(AS_OF_DATE=Date(\"2000-01-01\", dateformat\"y-m-d\"), \r\n\t\t\t\t\t\t\tID = 11:1:22,\r\n\t\t\t\t\t\t\tCLASSIFICATION=repeat([\r\n\t\"Region A\",\"Region B\", \"Region C\"], inner=4),\r\n\t\t\t\t\t\t\tCATEGORY=repeat([\r\n\t\"Region A\",\"Region B\", \"Region C\"], inner=4),\r\n\t\t\t\t\t\t\tSTATUS=\"A\",\r\n\t\t\t\t\t\t\tDESCR=[\r\n\"Boston\",\"New York\",\"Philadelphia\",\"Cleveland\",\"Richmond\",\r\n\"Atlanta\",\"Chicago\",\"St. Louis\",\"Minneapolis\",\"Kansas City\",\r\n\"Dallas\",\"San Francisco\"],\r\n\t\t\t\t\t\t\tLOCA_TYPE=\"Physical\");\r\nlocation[:,:]","category":"page"},{"location":"tutorials/selfservice/#visuals","page":"Self-Service Data Analytic","title":"visuals","text":"","category":"section"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"using DataFrames, Plots, Dates\r\n# create dummy data\r\naccounts = DataFrame(AS_OF_DATE=Date(\"1900-01-01\", dateformat\"y-m-d\"), \r\n\t\t\t\t\tID = 11000:1000:45000,\r\n\t\t\t\t\tCLASSIFICATION=repeat([\r\n\t\t\"OPERATING_EXPENSES\",\"NON-OPERATING_EXPENSES\", \"ASSETS\",\"LIABILITIES\",\r\n\t\t\"NET_WORTH\",\"STATISTICS\",\"REVENUE\"\r\n\t\t], inner=5),\r\n\tCATEGORY=[\r\n\t\t\"Travel\",\"Payroll\",\"non-Payroll\",\"Allowance\",\"Cash\",\r\n\t\t\"Facility\",\"Supply\",\"Services\",\"Investment\",\"Misc.\",\r\n\t\t\"Depreciation\",\"Gain\",\"Service\",\"Retired\",\"Fault.\",\r\n\t\t\"Receipt\",\"Accrual\",\"Return\",\"Credit\",\"ROI\",\r\n\t\t\"Cash\",\"Funds\",\"Invest\",\"Transfer\",\"Roll-over\",\r\n\t\t\"FTE\",\"Members\",\"Non_Members\",\"Temp\",\"Contractors\",\r\n\t\t\"Sales\",\"Merchant\",\"Service\",\"Consulting\",\"Subscriptions\"\r\n\t],\r\n\tSTATUS=\"A\",\r\n\tDESCR=repeat([\r\n\t\t\"operating expenses\",\"non-operating expenses\",\r\n\t\t\"assets\",\"liability\",\"net-worth\",\"stats\",\"revenue\"\r\n\t], inner=5),\r\n\tACCOUNT_TYPE=repeat([\r\n\t\"E\",\"E\",\"A\",\"L\",\"N\",\"S\",\"R\"\r\n\t\t\t\t],inner=5));\r\ndept = DataFrame(AS_OF_DATE=Date(\"2000-01-01\", dateformat\"y-m-d\"), \r\n\t\t\t\t\t\t\tID = 1100:100:1500,\r\n\t\t\t\t\t\t\tCLASSIFICATION=[\r\n\t\"SALES\",\"HR\", \"IT\",\"BUSINESS\",\"OTHERS\"\r\n\t],\r\n\t\t\t\t\t\t\tCATEGORY=[\r\n\t\"sales\",\"human_resource\",\"IT_Staff\",\"business\",\"others\"\r\n\t],\r\n\t\t\t\t\t\t\tSTATUS=\"A\",\r\n\t\t\t\t\t\t\tDESCR=[\r\n\t\"Sales & Marketing\",\"Human Resource\",\"Infomration Technology\",\"Business leaders\",\"other temp\"\r\n\t],\r\n\t\t\t\t\t\t\tDEPT_TYPE=[\r\n\t\"S\",\"H\",\"I\",\"B\",\"O\"]);\r\nlocation = DataFrame(AS_OF_DATE=Date(\"2000-01-01\", dateformat\"y-m-d\"), \r\n\t\t\t\t\t\t\tID = 11:1:22,\r\n\t\t\t\t\t\t\tCLASSIFICATION=repeat([\r\n\t\"Region A\",\"Region B\", \"Region C\"], inner=4),\r\n\t\t\t\t\t\t\tCATEGORY=repeat([\r\n\t\"Region A\",\"Region B\", \"Region C\"], inner=4),\r\n\t\t\t\t\t\t\tSTATUS=\"A\",\r\n\t\t\t\t\t\t\tDESCR=[\r\n\"Boston\",\"New York\",\"Philadelphia\",\"Cleveland\",\"Richmond\",\r\n\"Atlanta\",\"Chicago\",\"St. Louis\",\"Minneapolis\",\"Kansas City\",\r\n\"Dallas\",\"San Francisco\"],\r\n\t\t\t\t\t\t\tLOCA_TYPE=\"Physical\");\r\np1 = plot((combine(groupby(accounts, :CLASSIFICATION), nrow)).nrow,(combine(groupby(accounts, :CLASSIFICATION), nrow)).CLASSIFICATION, seriestype=scatter, label = \"# of accounts by classification\", xlabel = \"# of accounts\", ylabel=\"Class\", xlims = (0, 5.5))\r\n\tp2 = plot((combine(groupby(dept, :CLASSIFICATION), nrow)).nrow,(combine(groupby(dept, :CLASSIFICATION), nrow)).CLASSIFICATION, seriestype=scatter, label = \"# of dept by classification\", xlabel = \"# of depts\", ylabel=\"Class\", xlims = (0, 2))\r\n\tp3 = plot((combine(groupby(accounts, :CLASSIFICATION), nrow)).nrow,(combine(groupby(location, :CLASSIFICATION), nrow)).CLASSIFICATION, seriestype=scatter, label = \"# of locations by classification\", xlabel = \"# of locations\", ylabel=\"Class\", xlims = (1, 6.5))\r\nplot(p1, p2, p3, layout = (3, 1), legend = false)\r\n","category":"page"},{"location":"tutorials/selfservice/#Finance-Ledger-,-Balance-Sheet,-Income-Statement-and-Cash-Flow","page":"Self-Service Data Analytic","title":"Finance Ledger , Balance Sheet, Income Statement and Cash Flow","text":"","category":"section"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"below is sample Finance Ledger Data","category":"page"},{"location":"tutorials/selfservice/","page":"Self-Service Data Analytic","title":"Self-Service Data Analytic","text":"using DataFrames, Plots, Dates\r\n# create dummy data\r\naccounts = DataFrame(AS_OF_DATE=Date(\"1900-01-01\", dateformat\"y-m-d\"), \r\n\t\t\t\t\tID = 11000:1000:45000,\r\n\t\t\t\t\tCLASSIFICATION=repeat([\r\n\t\t\"OPERATING_EXPENSES\",\"NON-OPERATING_EXPENSES\", \"ASSETS\",\"LIABILITIES\",\r\n\t\t\"NET_WORTH\",\"STATISTICS\",\"REVENUE\"\r\n\t\t], inner=5),\r\n\tCATEGORY=[\r\n\t\t\"Travel\",\"Payroll\",\"non-Payroll\",\"Allowance\",\"Cash\",\r\n\t\t\"Facility\",\"Supply\",\"Services\",\"Investment\",\"Misc.\",\r\n\t\t\"Depreciation\",\"Gain\",\"Service\",\"Retired\",\"Fault.\",\r\n\t\t\"Receipt\",\"Accrual\",\"Return\",\"Credit\",\"ROI\",\r\n\t\t\"Cash\",\"Funds\",\"Invest\",\"Transfer\",\"Roll-over\",\r\n\t\t\"FTE\",\"Members\",\"Non_Members\",\"Temp\",\"Contractors\",\r\n\t\t\"Sales\",\"Merchant\",\"Service\",\"Consulting\",\"Subscriptions\"\r\n\t],\r\n\tSTATUS=\"A\",\r\n\tDESCR=repeat([\r\n\t\t\"operating expenses\",\"non-operating expenses\",\r\n\t\t\"assets\",\"liability\",\"net-worth\",\"stats\",\"revenue\"\r\n\t], inner=5),\r\n\tACCOUNT_TYPE=repeat([\r\n\t\"E\",\"E\",\"A\",\"L\",\"N\",\"S\",\"R\"\r\n\t\t\t\t],inner=5));\r\ndept = DataFrame(AS_OF_DATE=Date(\"2000-01-01\", dateformat\"y-m-d\"), \r\n\t\t\t\t\t\t\tID = 1100:100:1500,\r\n\t\t\t\t\t\t\tCLASSIFICATION=[\r\n\t\"SALES\",\"HR\", \"IT\",\"BUSINESS\",\"OTHERS\"\r\n\t],\r\n\t\t\t\t\t\t\tCATEGORY=[\r\n\t\"sales\",\"human_resource\",\"IT_Staff\",\"business\",\"others\"\r\n\t],\r\n\t\t\t\t\t\t\tSTATUS=\"A\",\r\n\t\t\t\t\t\t\tDESCR=[\r\n\t\"Sales & Marketing\",\"Human Resource\",\"Infomration Technology\",\"Business leaders\",\"other temp\"\r\n\t],\r\n\t\t\t\t\t\t\tDEPT_TYPE=[\r\n\t\"S\",\"H\",\"I\",\"B\",\"O\"]);\r\nlocation = DataFrame(AS_OF_DATE=Date(\"2000-01-01\", dateformat\"y-m-d\"), \r\n\t\t\t\t\t\t\tID = 11:1:22,\r\n\t\t\t\t\t\t\tCLASSIFICATION=repeat([\r\n\t\"Region A\",\"Region B\", \"Region C\"], inner=4),\r\n\t\t\t\t\t\t\tCATEGORY=repeat([\r\n\t\"Region A\",\"Region B\", \"Region C\"], inner=4),\r\n\t\t\t\t\t\t\tSTATUS=\"A\",\r\n\t\t\t\t\t\t\tDESCR=[\r\n\"Boston\",\"New York\",\"Philadelphia\",\"Cleveland\",\"Richmond\",\r\n\"Atlanta\",\"Chicago\",\"St. Louis\",\"Minneapolis\",\"Kansas City\",\r\n\"Dallas\",\"San Francisco\"],\r\n\t\t\t\t\t\t\tLOCA_TYPE=\"Physical\");\r\nledger = DataFrame(\r\n\t\tLEDGER = String[], FISCAL_YEAR = Int[], PERIOD = Int[], ORGID = String[],\r\n\t\tOPER_UNIT = String[], ACCOUNT = Int[], DEPT = Int[], LOCATION = Int[], \t\r\n\t\tPOSTED_TOTAL = Float64[]\r\n\t);\r\n\t# create 2020 Period 1-12 Actuals Ledger \r\n\tl = \"Actuals\";\r\n\tfy = 2020;\r\n\tfor p = 1:12\r\n\t\tfor i = 1:10^5\r\n\t\tpush!(ledger, (l, fy, p, \"ABC Inc.\", rand(location.CATEGORY),\r\n\t\t\trand(accounts.ID), rand(dept.ID), rand(location.ID), rand()*10^8))\r\n\t\tend\r\n\tend\r\n\t# create 2021 Period 1-4 Actuals Ledger \r\n\tl = \"Actuals\";\r\n\tfy = 2021;\r\n\tfor p = 1:4\r\n\t\tfor i = 1:10^5\r\n\t\tpush!(ledger, (l, fy, p, \"ABC Inc.\", rand(location.CATEGORY),\r\n\t\t\trand(accounts.ID), rand(dept.ID), rand(location.ID), rand()*10^8))\r\n\t\tend\r\n\tend\r\n\t# create 2021 Period 1-4 Budget Ledger \r\n\tl = \"Budget\";\r\n\tfy = 2021;\r\n\tfor p = 1:12\r\n\t\tfor i = 1:10^5\r\n\t\tpush!(ledger, (l, fy, p, \"ABC Inc.\", rand(location.CATEGORY),\r\n\t\t\trand(accounts.ID), rand(dept.ID), rand(location.ID), rand()*10^8))\r\n\t\tend\r\n\tend\r\nledger[:,:]\r\n\r\n# create default binding values/params\r\nusing PlutoUI\r\n\r\n## WARNING\r\n## These bind variable will throw in error in documentation\r\n## however, these runs fine on Pluto notebooks and provide a slider to change values dynamically\r\n\r\n# @bind ld Select([\"Actuals\", \"Budget\"])\r\n# @bind rg Select([\"Region A\", \"Region B\", \"Region C\"])\r\n# @bind yr Slider(2020:1:2021, default=2020, show_value=true)\r\n# @bind qtr Slider(1:1:4, default=1, show_value=true)\r\n# @bind ld_p Select([\"Actuals\", \"Budget\"])\r\n# @bind yr_p Slider(2020:1:2021, default=2021, show_value=true)\r\n# @bind rg_p Select([\"Region A\", \"Region B\", \"Region C\"])\r\n# @bind ldescr Select(unique(location.DESCR))\r\n# @bind adescr Select(unique(accounts.CLASSIFICATION))\r\n# @bind ddescr Select(unique(dept.CLASSIFICATION))\r\n\r\nld = \"Actuals\"\r\nrg = \"Region B\"\r\nyr = 2020\r\nqtr = 1\r\nld_p = \"Actuals\"\r\nrg_p = \"Region B\"\r\nyr_p = 2020\r\nqtr_p = 1\r\nldescr = unique(location.DESCR)\r\nadescr = unique(accounts.CLASSIFICATION)\r\nddescr = unique(dept.CLASSIFICATION)\r\n\r\n########################\r\n##### BALANCE SHEET ####\r\n########################\r\n\r\n# rename dimensions columns for innerjoin\r\ndf_accounts = rename(accounts, :ID => :ACCOUNTS_ID, :CLASSIFICATION => :ACCOUNTS_CLASSIFICATION, :CATEGORY => :ACCOUNTS_CATEGORY, :DESCR => :ACCOUNTS_DESCR);\r\ndf_dept = rename(dept, :ID => :DEPT_ID, :CLASSIFICATION => :DEPT_CLASSIFICATION, :CATEGORY => :DEPT_CATEGORY, :DESCR => :DEPT_DESCR);\r\ndf_location = rename(location, :ID => :LOCATION_ID, :CLASSIFICATION => :LOCATION_CLASSIFICATION, :CATEGORY => :LOCATION_CATEGORY, :DESCR => :LOCATION_DESCR);\r\n\r\n# create a function which converts accounting period to Quarter\r\nfunction periodToQtr(x)\r\n\tif x ∈ 1:3\r\n\t\treturn 1\r\n\telseif x ∈ 4:6\r\n\t\treturn 2\r\n\telseif x ∈ 7:9\r\n\t\treturn 3\r\n\telse return 4\r\n\tend\r\n\tend\r\n\r\n##############################################################\r\n# create a new dataframe to join all chartfields with ledger #\r\n##############################################################\r\n\r\ndf_ledger = innerjoin(\r\n\t\tinnerjoin(\r\n\t\t\tinnerjoin(ledger, df_accounts, on = [:ACCOUNT => :ACCOUNTS_ID], makeunique=true),\r\n\t\t\tdf_dept, on = [:DEPT => :DEPT_ID], makeunique=true), df_location,\r\n\ton = [:LOCATION => :LOCATION_ID], makeunique=true);\r\n\ttransform!(df_ledger, :PERIOD => ByRow(periodToQtr) => :QTR);\r\n\r\nfunction numToCurrency(x)\r\n\t\treturn string(\"USD \",round(x/10^6; digits = 2), \"m\")\r\n\tend\r\n\tgdf = groupby(df_ledger, [:LEDGER, :FISCAL_YEAR, :QTR, :OPER_UNIT, :ACCOUNTS_CLASSIFICATION, :DEPT_CLASSIFICATION, \r\n\t\t\t# :LOCATION_CLASSIFICATION,\r\n\t\t\t:LOCATION_DESCR]);\r\n\tgdf_plot = combine(gdf, :POSTED_TOTAL => sum => :TOTAL);\r\n\r\n\tselect(gdf_plot[(\r\n\t\t\t\t(gdf_plot.FISCAL_YEAR .== yr)\r\n\t\t\t\t.&\r\n\t\t\t\t(gdf_plot.QTR .== qtr)\r\n\t\t\t\t.&\r\n\t\t\t\t(gdf_plot.LEDGER .== ld)\r\n\t\t\t\t.&\r\n\t\t\t\t(gdf_plot.OPER_UNIT .== rg)\r\n\t\t\t\t),:], \r\n\t\t:FISCAL_YEAR => :FY,\r\n\t\t:QTR => :Qtr,\r\n\t\t:OPER_UNIT => :Org,\r\n\t\t:ACCOUNTS_CLASSIFICATION => :Accounts,\r\n\t\t:DEPT_CLASSIFICATION => :Dept,\r\n\t\t# :LOCATION_CLASSIFICATION => :Region,\r\n\t\t:LOCATION_DESCR => :Loc,\r\n\t\t:TOTAL => ByRow(numToCurrency) => :TOTAL)\r\n\r\n########################\r\n### Income Statement ###\r\n########################\r\n\r\nselect(gdf_plot[(\r\n\t\t\t\t(gdf_plot.FISCAL_YEAR .== yr)\r\n\t\t\t\t.&\r\n\t\t\t\t(gdf_plot.QTR .== qtr)\r\n\t\t\t\t.&\r\n\t\t\t\t(gdf_plot.LEDGER .== ld)\r\n\t\t\t\t.&\r\n\t\t\t\t(gdf_plot.OPER_UNIT .== rg)\r\n\t\t\t\t.&\r\n\t\t\t\t(in.(gdf_plot.ACCOUNTS_CLASSIFICATION, Ref([\"ASSETS\", \"LIABILITIES\", \"REVENUE\",\"NET_WORTH\"])))\r\n\t\t\t\t),:], \r\n\t\t:FISCAL_YEAR => :FY,\r\n\t\t:QTR => :Qtr,\r\n\t\t:OPER_UNIT => :Org,\r\n\t\t:ACCOUNTS_CLASSIFICATION => :Accounts,\r\n\t\t# :DEPT_CLASSIFICATION => :Dept,\r\n\t\t# :LOCATION_CLASSIFICATION => :Region,\r\n\t\t# :LOCATION_DESCR => :Loc,\r\n\t\t:TOTAL => ByRow(numToCurrency) => :TOTAL)\r\n\r\n########################\r\n##### CASH FLOW ########\r\n########################\r\n\r\nselect(gdf_plot[(\r\n\t\t\t\t(gdf_plot.FISCAL_YEAR .== yr)\r\n\t\t\t\t.&\r\n\t\t\t\t(gdf_plot.QTR .== qtr)\r\n\t\t\t\t.&\r\n\t\t\t\t(gdf_plot.LEDGER .== ld)\r\n\t\t\t\t.&\r\n\t\t\t\t(gdf_plot.OPER_UNIT .== rg)\r\n\t\t\t\t.&\r\n\t\t\t\t(in.(gdf_plot.ACCOUNTS_CLASSIFICATION, Ref([\"NON-OPERATING_EXPENSES\",\"OPERATING_EXPENSES\"\t])))\r\n\t\t\t\t),:], \r\n\t\t:FISCAL_YEAR => :FY,\r\n\t\t:QTR => :Qtr,\r\n\t\t:OPER_UNIT => :Org,\r\n\t\t:ACCOUNTS_CLASSIFICATION => :Accounts,\r\n\t\t# :DEPT_CLASSIFICATION => :Dept,\r\n\t\t# :LOCATION_CLASSIFICATION => :Region,\r\n\t\t# :LOCATION_DESCR => :Loc,\r\n\t\t:TOTAL => ByRow(numToCurrency) => :TOTAL)\r\n\r\n\r\n########################\r\n##### Ledger Visual ####\r\n########################\r\n\r\nplot_data = gdf_plot[(\r\n\t\t(gdf_plot.FISCAL_YEAR .== yr_p)\r\n\t\t.&\r\n\t\t(gdf_plot.LEDGER .== ld_p)\r\n\t\t.&\r\n\t\t(gdf_plot.OPER_UNIT .== rg_p)\r\n\t\t.&\r\n\t\t(gdf_plot.LOCATION_DESCR .== ldescr)\r\n\t\t.&\r\n\t\t(gdf_plot.DEPT_CLASSIFICATION .== ddescr)\r\n\t\t.&\r\n\t\t(gdf_plot.ACCOUNTS_CLASSIFICATION .== adescr))\r\n\t\t, :];\r\n\t# @df plot_data scatter(:QTR, :TOTAL/10^8, title = \"Finance Ledger Data\", xlabel=\"Quarter\", ylabel=\"Total (in USD million)\", label=\"$ld_p Total by $yr_p for $rg_p\")\r\n\t@df plot_data plot(:QTR, :TOTAL/10^8, title = \"Finance Ledger Data\", xlabel=\"Quarter\", ylabel=\"Total (in USD million)\", \r\n\t\tlabel=[\r\n\t\t\t\"$ld_p by $yr_p for $rg_p $ldescr $adescr $ddescr\"\r\n\t\t\t],\r\n\t\tlw=3)\r\n\t\t\r\n#################################\r\n## Actual vs Budget Comparison ##\r\n#################################\r\n\r\nplot_data_a = gdf_plot[(\r\n\t\t(gdf_plot.FISCAL_YEAR .== yr_p)\r\n\t\t.&\r\n\t\t(gdf_plot.LEDGER .== \"Actuals\")\r\n\t\t.&\r\n\t\t(gdf_plot.OPER_UNIT .== rg_p)\r\n\t\t.&\r\n\t\t(gdf_plot.LOCATION_DESCR .== ldescr)\r\n\t\t.&\r\n\t\t(gdf_plot.DEPT_CLASSIFICATION .== ddescr)\r\n\t\t.&\r\n\t\t(gdf_plot.ACCOUNTS_CLASSIFICATION .== adescr))\r\n\t\t, :];\r\n\t# @df plot_data scatter(:QTR, :TOTAL/10^8, title = \"Finance Ledger Data\", xlabel=\"Quarter\", ylabel=\"Total (in USD million)\", label=\"$ld_p Total by $yr_p for $rg_p\")\r\n\tplot_data_b = gdf_plot[(\r\n\t\t(gdf_plot.FISCAL_YEAR .== yr_p)\r\n\t\t.&\r\n\t\t(gdf_plot.LEDGER .== \"Budget\")\r\n\t\t.&\r\n\t\t(gdf_plot.OPER_UNIT .== rg_p)\r\n\t\t.&\r\n\t\t(gdf_plot.LOCATION_DESCR .== ldescr)\r\n\t\t.&\r\n\t\t(gdf_plot.DEPT_CLASSIFICATION .== ddescr)\r\n\t\t.&\r\n\t\t(gdf_plot.ACCOUNTS_CLASSIFICATION .== adescr))\r\n\t\t, :];\r\n\t# @df plot_data scatter(:QTR, :TOTAL/10^8, title = \"Finance Ledger Data\", xlabel=\"Quarter\", ylabel=\"Total (in USD million)\", label=\"$ld_p Total by $yr_p for $rg_p\")\r\n\t@df plot_data_a plot(:QTR, :TOTAL/10^8, title = \"Finance Ledger Data\", xlabel=\"Quarter\", ylabel=\"Total (in USD million)\", \r\n\t\tlabel=[\r\n\t\t\t\"Actuals by $yr_p for $rg_p $ldescr $adescr $ddescr\"\r\n\t\t\t],\r\n\t\tlw=3)\r\n\t@df plot_data_b plot!(:QTR, :TOTAL/10^8, title = \"Finance Ledger Data\", xlabel=\"Quarter\", ylabel=\"Total (in USD million)\", \r\n\t\tlabel=[\r\n\t\t\t\"Budget by $yr_p for $rg_p $ldescr $adescr $ddescr\"\r\n\t\t\t],\r\n\t\tlw=3)\r\n","category":"page"},{"location":"tutorials/analytic/#p-value,-null-hypothesis-and-real-time-analytics-(onlinestat)","page":"p-value, null hypothesis and real time analytic","title":"p-value, null hypothesis and real time analytics (onlinestat)","text":"","category":"section"},{"location":"tutorials/aboutgl/#About-General-Ledger","page":"About GL","title":"About General Ledger","text":"","category":"section"},{"location":"tutorials/aboutgl/#what-is-General-Ledger","page":"About GL","title":"what is General Ledger","text":"","category":"section"},{"location":"tutorials/aboutgl/","page":"About GL","title":"About GL","text":"GL serves as core of any Financial Management system.","category":"page"},{"location":"tutorials/aboutgl/","page":"About GL","title":"About GL","text":"It's objective is to keep detail and summary accounting information and produce numerous financial reports for your organization. Typical, you will hear Cash Flow, Income and Balance Sheet statements as SEC filings as financial reports indicating Organizations financial growth. In general, accountants, statistical analysts strongly feel that financial reports from General Ledger are true indicator of organizations growth.","category":"page"},{"location":"tutorials/aboutgl/","page":"About GL","title":"About GL","text":"Often Small, Medium organizations see General Ledger as luxury application, the reason behind this belief is, it's not easy to setup and start using General Accounting principles to organize and operate business process to implement and follow accounting processes on daily basis.","category":"page"},{"location":"tutorials/aboutgl/","page":"About GL","title":"About GL","text":"Big organizations do not have option to skip General Ledger implementation, because, GL is the only way to manage their business processes, this is why it's normal for big organizations to invest in Big ERP systems like SAP, Oracle, PeopleSoft, JDEdwards, Workday, Coupa etc.","category":"page"},{"location":"tutorials/aboutgl/","page":"About GL","title":"About GL","text":"However, recent popularity of new generations of ERP software like Quickbook, Tally etc. is the proof the implementing General Ledger accounting processes is the way to manage any size of organization. ","category":"page"},{"location":"tutorials/aboutgl/","page":"About GL","title":"About GL","text":"Even a small vendor now a days use mobile devices to scan vendor invoice, prefer to pay online and record transactions to appropriate General Ledger accounts.","category":"page"},{"location":"tutorials/aboutgl/","page":"About GL","title":"About GL","text":"\"Read, Write & Understand\" are three important aspects of data. ERP users realize how important it is to invest in a system where they can write their business processes data.","category":"page"},{"location":"tutorials/aboutgl/","page":"About GL","title":"About GL","text":"Writing business processes data/transactions, helps Business understand their processes and improved on it. ERP Data Analysis brings extraordinary benefit to manage business efficiently.","category":"page"},{"location":"tutorials/aboutgl/#Technical-Analysis","page":"About GL","title":"Technical Analysis","text":"","category":"section"},{"location":"tutorials/aboutgl/","page":"About GL","title":"About GL","text":"is the process of forecasting future Organization growth or stock prices based on studying (using advance charting and applying mathematical formulas) past stock prices and trading volume. Technical analysis strongly believes that at any given point of time, stock price and trading volume reflects it current value and charting accurately captures all factors which can cause upwards or downwards stock prices movement.","category":"page"},{"location":"tutorials/aboutgl/#Fundamental-Analysis","page":"About GL","title":"Fundamental Analysis","text":"","category":"section"},{"location":"tutorials/aboutgl/","page":"About GL","title":"About GL","text":"is the process of forecasting future Organization growth or stock prices based on studying company financial statements like Income Statements, Cash Flow and Balance Sheets.","category":"page"},{"location":"tutorials/aboutgl/#Techno-Fundamental-Analysis","page":"About GL","title":"Techno-Fundamental Analysis","text":"","category":"section"},{"location":"tutorials/aboutgl/","page":"About GL","title":"About GL","text":"In this notebook and all my follow-up GL notebooks, I am proposing to use 3rd type of analysis. With the use of Machine Learning, one can apply ML algorithms to GL and SUB Ledger (accounting entries) Books. Techno-fundamental analysis is not new, however, its seen very difficult because its requires big data and large computation.","category":"page"},{"location":"tutorials/aboutgl/","page":"About GL","title":"About GL","text":"Julia language provides fast computations for large data sets and great assets for Statistical programming.","category":"page"},{"location":"tutorials/aboutgl/#Abstract","page":"About GL","title":"Abstract","text":"","category":"section"},{"location":"tutorials/aboutgl/","page":"About GL","title":"About GL","text":"In a nutshell, GL is simply about Credit & Debit, You Credit you saving accounts once you generate revenue on your sales, and make money. You debit your cash accounts because you have to pay your workforce, or invest in your assets.","category":"page"},{"location":"tutorials/aboutgl/","page":"About GL","title":"About GL","text":"Credit & Debit difference, is for you to keep, and totally up to you decide how to wisely spend you earnings. Obviously, its not this simple, its a typical for large Organizations to employ 1000+ people just to do these operations. Due to complexity of these business processes It's very easy to get distracted and lose focus, So throughout this MLforGL journey discussed in this package, we will stick to these fundamentals and quickly come back to core GL and avoid jumping into sub-ledger operations too much in depth.","category":"page"},{"location":"tutorials/elt/#ELT-vs-ETL.jl","page":"ELT vs ETL","title":"ELT vs ETL.jl","text":"","category":"section"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"ETL Data Warehouse vs ELT Data Lake debate, is like vim vs emacs, linux vs windows never ending discussions.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"It means different things and may represent different concepts, but end of the day leads to one conclusion.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"Data is a mineral, if you handle it with care and delicacy, polish and move it to a fine safe enclosure, it will age as fine gold. ","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"<font color=brown><b> Amit Shukla</b></font>\r\n<br>","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"In this lesson, we will discuss different strategies to Extract, Transform, Load data from different sources to different enclosures. You will find examples to address different type of extract, data pull strategies with code.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"Why this package? There are a dozen ETL/ELT and Data warehouse/ Data lake solutions available in the market today. All of them are extremely capable of extraction, load and transforming almost any type of data structure like structured, un-structured, binary, BLOB, sound, image or simple text in large quantities.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"This package neither challenges or aims to build anything different. Instead, this package will use existing RDBMS, DataLakes, or Document databases available in the market.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"This package should be seen as providing a DataType environment, where we can first understand and define subject data structure, then do ELT operations on it. This is what I meant earlier by saying handle with care and delicacy.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"Inheriting behavior is much more important than being able to inherit structure.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"Just to give an example, Normally, we ingest all vendor tables/transactions into a Data warehouse or Data lake or any self-service environment, and then let SMEs run meaningful analytics on it. instead, Lets first define a Vendor DataType and then build ELT or ETL operations on it. This simple concept will age your data to fine gold and SME will be able to do self-service analytics with worrying too much learning data structure and entity relationships.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"Another example is,  Instead of loading all your accounting data into RDBMS tables, developers take time to pre-define an accounting Data Structure such as JOURNALS, LEDGER, ACCOUNTINGLINES, CHARTFIELDs and HIERARCHY data types, then ELT data into these Data Structures and push it to the reporting database. This will lead to a much powerful driverless self-service live reporting/ predictive analytics environment.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"In the following sections, we will discuss few ETL & ELT strategies.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"","category":"page"},{"location":"tutorials/elt/#Extract","page":"ELT vs ETL","title":"Extract","text":"","category":"section"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"Data Extraction from a known source is easy, tough part is, automating to fetch data on pre-defined schedules. Further, most difficult task is to identify deltas on every single data row during extract execution and pull/push only changed datasets.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"Stage or not to stage: keeping an original copy of data into a local/hadoop directory or storing the first original copy in RDBMS tables brings extra benefit to your Analytics. You will always be able to go back in time and restore from originals, however, it also brings unmanageable clutter, junk and storage costs.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"Before trying to read data from source, you must think, how would you want to use it in near future.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"You can store the original copy as-is to a directory or RDBMS table. This works well, when you are dealing with txt, image files. Storage is cheaper than computing.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"for example","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"consider storing a copy of the APPL SEC Balance sheet filing PDF from the internet rather than building NLP AI to read certain dollar amounts or quantities from a PDF.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"Your AI scripts will bill more for compute hours than storing a few extra KBs.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"on the other hand, reading 5 lines from 5000 pages PDF, doesn't justify the need to store the entire document. Instead, use a web crawler, good OCR or text reader AI-bot to fetch data that is meaningful to you.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"while reading data from a RDBMS, consider using a where lastupdatedate > lastrundate to fetch only deltas.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"storing <last_run_date> will be discussed in LOAD section later.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"Let's look into few example used to extract different type of data.","category":"page"},{"location":"tutorials/elt/#add-GeneralLedger.jl-package","page":"ELT vs ETL","title":"add GeneralLedger.jl package","text":"","category":"section"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"# first, add GeneralLedger.jl package to your environment\r\nusing Pkg\r\nPkg.add(url=\"https://github.com/AmitXShukla/GeneralLedger.jl\")","category":"page"},{"location":"tutorials/elt/#file-download","page":"ELT vs ETL","title":"file download","text":"","category":"section"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"download a simple file from a website, FTP location","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"# let's download Apple INC Q2 2021 SEC Filing document\r\n# downloading from website\r\n# download(url::AbstractString, [path::AbstractString = tempname()]) -> path\r\nusing GeneralLedger\r\nfl = getFile(\"https://s2.q4cdn.com/470004039/files/doc_financials/2021/q2/FY21-Q2-Consolidated-Financial-Statements.pdf\", \"FY21-Q2-Consolidated-Financial-Statements.pdf\");\r\nfilesize(fl)","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"download using curl/wget","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"# let's download Apple INC Q2 2021 SEC Filing document\r\n# downloading using curl/wget\r\n# wrap system commands (curl or wget) inside backticks\r\n\r\ndownloadFileCommand = `curl https://s2.q4cdn.com/470004039/files/doc_financials/2021/q2/FY21-Q2-Consolidated-Financial-Statements.pdf --output apple_q2-21-10Q.pdf`\r\nrun(downloadFileCommand)","category":"page"},{"location":"tutorials/elt/#auto_data_pull","page":"ELT vs ETL","title":"automating data pull","text":"","category":"section"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"In this section, we will build a simple script, which reads input (urls) file, and downloads all files.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"to scrap all available links from webpage tinto a local txt file, see Web crawl & Web Scraping section below.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"# use this code, to read all links from a txt file \r\n# and download each file one by one\r\nusing GeneralLedger\r\ngetPullFiles(\"c:\\\\amit.la\\\\file_name.txt\")","category":"page"},{"location":"tutorials/elt/#scheduling-automated-data-pull","page":"ELT vs ETL","title":"scheduling automated data pull","text":"","category":"section"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"In this section, we will learn different options to automate data pull scripts to run on recurring schedule.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"First and preferred option is, user can setup a cron job on Linux or powershell script on windows.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"# setup a Linux cron job\r\ncrontab -e\r\n# minute hour day-of-month month day-of-week command\r\n0 10 * * * Julia autopull.jl","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"and if you must do this in Julia, second option is to use native Julia Lang sleep, timer or scheduler functions.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"# code credit - discourse.julialang.org thread\r\nresult = nothing\r\ndone = false\r\nwhile !done\r\n    try \r\n        result = # invoke function that may fail\r\n        done = true\r\n    catch e\r\n        sleep(86400)  # sleep for 1 day(=86400 seconds) before restarting\r\n     end\r\nend","category":"page"},{"location":"tutorials/elt/#RDBMS,-HIVE","page":"ELT vs ETL","title":"RDBMS, HIVE","text":"","category":"section"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"connecting to Oracle, MY SQL or MS SQL Server","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"In this section, below are few examples showing, how to connect to RDBMS SQL databases using ODBC.jl package.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"Please see, user can directly use ODBC.jl package instead of GeneralLedger.jl wrapper functions as shown below. GeneralLedger.jl created this wrapper functions just to enforce and implement standard community guidelines and best practices.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"For example     - It's not a good idea to pass Database credentials to functions directly, instead, credentials should be kept in separate environment file.     - Similarily, keeping SQLs in xls/txt file is better than using variable to hold SQLs.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"First create a txt file to hold database credentials and make sure DSN are already created in computing environment.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"environment.txt","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"user=username\r\npwd=password\r\ndsn=userdsnname\r\nhive=hdinsightstr\r\nport=portnumber","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"using GeneralLedger\r\ngetDSNs()\r\ngetDrivers()","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"Next create txt file(s) to hold database SQLs.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"sqls.txt","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"createTable1=INSERT INTO table1 (column1) SELECT table2.column1 FROM table2 WHERE table2.column1 > 100;\r\nreadTable1=SELECT * FROM table1;\r\nupdateTable1=UPDATE table SET column1 = value1, column2 = value2, ... WHERE condition;\r\nupsertTable1=BEDIN tran IF EXISTS (SELECT * FROM table1 WITH (updlock,serializable) WHERE key = @key) BEGIN UDPATE table1 SET ... WHERE key = @key END ELSE BEGIN INSERT INTO table1 (key, ...) VALUES (@key, ...) END COMMIT TRAN\r\nsoftDeleteTable1=UPDATE table SET deleted=True, ... WHERE condition;\r\nhardDeleteTable1=delete * from table1 where table1.column1 > 100","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"using GeneralLedger, DataFrames\r\nconn = getDBConnection(\"environment.txt\")\r\nsql = getSQLs(\"sqls.txt\")\r\ndf = runSQL(conn, sql.readTable1) |> DataFrame\r\n","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"when you are done with SQLs, don't forget to close DB connection.","category":"page"},{"location":"tutorials/elt/#close-DB-Connections","page":"ELT vs ETL","title":"close DB Connections","text":"","category":"section"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"using GeneralLedger\r\nsetCloseConnection()","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"using ODBC to insert data into RDBMS may be very slow operation, see below LOAD section for other methods/strategies to load bulk data.","category":"page"},{"location":"tutorials/elt/#JSON","page":"ELT vs ETL","title":"JSON","text":"","category":"section"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"# use this code, to download BITCOIN market price into a dataframe\r\n# and download data in csv format\r\nusing GeneralLedger\r\ndf = getJSONintoDataFrame(\"https://api.coindesk.com/v1/bpi/currentprice.json\", \"downloads/web\")","category":"page"},{"location":"tutorials/elt/#XML","page":"ELT vs ETL","title":"XML","text":"","category":"section"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"# use this code, to download XML into a dataframe\r\n# and download data in csv format\r\nusing GeneralLedger\r\ndf = getXMLintoDataFrame(\"https://www.clinicaltrials.gov/ct2/results/rss.xml?rcv_d=14&lup_d=&sel_rss=new14&cond=Coronavirus&count=10000\", \"downloads/web\")","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"","category":"page"},{"location":"tutorials/elt/#web_crawl","page":"ELT vs ETL","title":"Web crawl & Web Scraping","text":"","category":"section"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"We just looked at examples, how to download file(s) from website or FTP locations. However in some case, you may not know how many files are available for download.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"In this example below, we will use this GeneralLedger.jl function, which crawl through Apple INC SEC Filing web page (or any webpage), reads HTML and identify all PDF/XLSX or CSV files downloadable links.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"We will store these links into csv file and this file can be used in automating data pull, to automatically download all files at once.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"start a webdriver session","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"# you must have a valid webdriver session running on your machine\r\n# download a valid chromedriver version on your machine from this link\r\n# https://chromedriver.chromium.org/downloads (may vary)\r\n# after you download, open a terminal window & browe to directory\r\n# where chromedrive.exe is location and run\r\n# chromedriver.exe --url-base=/wd/hub\r\n# above command will start a chrome webdriver session on port 9515\r\n\r\nwdrvCommand = `chromedriver.exe --url-base=/wd/hub`\r\n# if you see an error below, that's because I didn't provide correct path\r\n# to find chromedriver.exe file\r\nrun(wdrvCommand)","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"web crawl & web scraping","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"# Call this function to crawl through a web page and download all file links\r\n# first parameter is webpage url, next parameter is list of all file extensions\r\n# where user wish to download followed by output directory path\r\nusing GeneralLedger\r\ngetWebLinks(\"https://investor.apple.com/investor-relations/default.aspx#tabs_content--2021\", [\"pdf\",\"csv\",\"xlsx\",\"xls\"], \"downloads/web\")","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"GeneralLedger getWebLinks function fetches and store these links into csv file, which is used in automating data pull, to automatically download all files at once.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"","category":"page"},{"location":"tutorials/elt/#Load","page":"ELT vs ETL","title":"Load","text":"","category":"section"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"Now once data is identified, we will need a storage system, typically a database, data warehouse or data lake to keep data. Before loading into a Target system, let's work on our load strategy.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"Think of these scenarios you will be dealing after data is loaded.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"simple excel files first row will be used as RDBMS table names. Often, RDBMS will change column headers and this will be a challenge to map with original excel files each time a newer file is downloaded.\nyou dont want to fetch the same file if it already exists in the local/hadoop directory.\nin case of RDBMS, you may want to mark each record with CRUD date (when a row was first created, updated and read. You may never want to hard delete a row, and just do a soft delete instead to hide from the user's view).","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"using ODBC to load BULK data could be very slow operations, instead Cloud data upload strategies are highly recommended to move data.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"For Example, using Oracle, Google or Azure cloud storage systems could be easier option to load huge datasets into RDBMs.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"Google Cloud SQL upload strategy","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"Oracle Cloud upload strategy","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"TODO: will update this section to show case how to use Julia to upload Big Data into cloud databases.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"First, we will create few METADAT tables to store LOAD information.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"Ideally, These METADATA tables should be stores in Target system database, however, just to showcase, data LOAD Strategy, in this case, We will use JULIADB to capture TABLES LOAD METADATA information.","category":"page"},{"location":"tutorials/elt/#meta_data_table","page":"ELT vs ETL","title":"METADATA tables","text":"","category":"section"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"METADATA.LOADTIME This table is used to store information related to each table METADATA. Everytime, after Data is Extracted and loaded into Target Database, these METADATA tables must be updated.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"name=tablename\r\nsor=source_system_name\r\nauthor=source_system_userid\r\nupdateAt=lastupddttm","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"METADATA.DATE_BASED_CDC create One METADATA file per table. This table is used to store information related to each table read from source through a date based CDC (Change data capture) logic. and next time, same date is used to pull incremental data from source system.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"For example, -  SELECT * FROM sourceDB.table1 WHERE sourceDB.table1.updateDttm > JULIADB.METADATA.DATE_BASED_CDC.table1.incrementDt","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"Everytime, after Data is Extracted and loaded into Target Database, these METADATA tables must be updated.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"name=tablename\r\nsor=source_system_name\r\nauthor=source_system_userid\r\nupdateAt=lastupddttm\r\nincrementDt=max_updateDt_at_source # Leave blank in case of KEYs based CDC\r\nsid=maxDourrogateID # unique numerical identifier per row, used in ETL Datawarehouse.\r\n                    # Leave blank is case of ELT Data lake","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"METADATA.KEYS_BASED_CDC create One METADATA file per table. This table is used to store information related to each table read from source through a date based CDC (Change data capture) logic. and next time, same date is used to pull incremental data from source system.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"For example, -  SELECT [key_columns] FROM sourceDB.table1 <MATCH> JULIADB.METADATA.DATE_BASED_CDC.table1.key1..2..3 => INSERT / UPDATE / UPSERT","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"Everytime, after Data is Extracted and loaded into Target Database, these METADATA tables must be updated.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"key1=primarykey\r\nkey2=primarykey\r\nkey3=primarykey\r\nauthor=source_system_userid\r\ncreateAt=currentdttm # do not update this, in case of an update\r\nupdateAt=currentdttm\r\nsid=maxDourrogateID # unique numerical identifier per row, used in ETL Datawarehouse.\r\n                    # Leave blank is case of ELT Data lake","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"using GeneralLedger\r\ngetDSNs()\r\ngetDrivers()","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"","category":"page"},{"location":"tutorials/elt/#Transform","page":"ELT vs ETL","title":"Transform","text":"","category":"section"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"What seems hardest, is the easiest part to deal with. Once a correct dataset is read and loaded into the system. There are several transformation techniques and tools available.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"In ELT like environments, Transformation is mostly done on Analytical tool, like Microsoft Power BI, Tableau, Oracle Analytics are extremely powerful and provide out of the box transformation techniques.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"However, here are some useful scripts, which can be run on local environment for data cleansing. These GeneralLedger.jl data cleansing/tranformation funcitons are extremely powerful when dealing with extreme large Big data sets.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"read all xls files from a directory getXLSinDirectory\nremoving unwanted chars in columns headers or rows setColNames\narrange words (remove unwanted chars, sort and return uppercase) getArrangedWords\nFuzzyWuzzy - finds closest match for a given string in data frame column getFuzzyWuzzy\nremoving missing, NA, Tokens getTokens, setRemoveTokens\nremoving words setRemoveText\nreplacing text setReplaceText\nidentifying duplicates getDuplicateRows\nidentifying key columns in dataset getKeyColumns\nremoving duplicates setRemDuplicateRows\ncategorizing data getCategoryData\ncreating Hierarchy, Tree like dimensional structure getTreeData\ncreating synthetic/masked reversible data (produces two files, one with masked data and original with masked data) getMaskedData","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"using GeneralLedger, DataFrames\r\n# getXLSinDirectory\r\n# read all xls files from a directory\r\ngetXLSinDirectory(\".\")\r\n\r\n# setColNames\r\n# Call this function to remove not-compatible SQL columns chars\r\nsetColNames(\"Amit Sh-ukla # \\$\")\r\n\r\n# getArrangedWords\r\n# Call this function to remove duplicates, unwanted symbols and return uppercase unique values\r\nwd = getArrangedWords(\"Amit ; Shukla SHUKLA Shukle , . AmIT Amit # Shuklam Amit ,\")\r\n\r\n# getFuzzyWuzzy\r\n# Call this function to find closest match for a given string in data frame column lookup\r\n# First parameter is the search string, second is the DataFrame followed by columnname in DataFrame which needs to be searched\r\ndf_dname = DataFrame(name=[\"John Doe\", \"Jen Doe\",\"MICHAEL Doe\", \"Jacob Doe\", \"Julia Dpe\", \"Michael Jackson\"],age=[35,26,35,10,5,45])\r\nwd = getFuzzyWuzzy(\"Mike Jackson\", df_dname, \"name\")\r\n\r\n# getTokens\r\n# Call this function to extract tokens from string (example - extract urls)\r\n# First parameter is the complete string text, next parameter is list of words to be removed.\r\nwd = getTokens(\"https://yahoo.com is the Yahoo website url\", url)\r\n\r\n# setRemoveTokens\r\n# Call this function to remove tokens\r\nwd = setRemoveTokens(\"Amit Shukla Shkla Los Angel Angeles\")\r\n\r\n# setRemoveText\r\n# Call this function to find and remove word in text string\r\n# First parameter is the complete string text, next parameter is list of words to be removed.\r\nwd = setRemoveText(\"Amit Shukla Shkla Los Angel Angeles\", [\"Shkla\", \"Angel\"])\r\n\r\n# setReplaceText\r\n# Call this function to find and replace word in text string\r\n# First parameter is the term to be replaced, next is the term replaced with followed by text string where text is searched and replaced.\r\nwd = setReplaceText(\"Shkla\",\"Shukla \",\"Amit Shkla Los Angeles\")\r\n\r\n# getDuplicateRows\r\n# Call this function to find duplicates in a data frame column based on columnnames (key columns)\r\ndf_dname = DataFrame(name=[\"John Doe\", \"John Doe\",\"MICHAEL Doe\", \"Jacob Doe\", \"Julia Dpe\", \"Michael Jackson\"],age=[35,35,35,10,5,45], state=[\"CA\",\"CA\",\"CA\",\"CA\",\"CO\",\"CA\"])\r\ndup = getDuplicateRows(df_dname, [\"name\",\"age\"])\r\n\r\n# getKeyColumns\r\n# Call this function to find key columns in a data frame\r\ndf_dname = DataFrame(name=[\"John Doe\", \"John Doe\",\"MICHAEL Doe\", \"Jacob Doe\", \"Julia Dpe\", \"Michael Jackson\"],age=[35,35,35,10,5,45], state=[\"CA\",\"CA\",\"CA\",\"CA\",\"CO\",\"CA\"])\r\nkcols = getKeyColumns(df_dname)\r\n\r\n# setRemDuplicateRows\r\n# Call this function to find & delete duplicates in a data frame column based on columnnames (key columns)\r\ndf_dname = DataFrame(name=[\"John Doe\", \"John Doe\",\"MICHAEL Doe\", \"Jacob Doe\", \"Julia Dpe\", \"Michael Jackson\"],age=[35,35,35,10,5,45], state=[\"CA\",\"CA\",\"CA\",\"CA\",\"CO\",\"CA\"])\r\ndup = setRemDuplicateRows(df_dname, [\"name\",\"age\"])\r\n\r\n# getCategoryData\r\n# Call this function to create a new column on DataFrame which provide a category based on ranges provided.\r\ndf_dname = DataFrame(name=[\"John Doe\", \"John Doe\",\"MICHAEL Doe\", \"Jacob Doe\", \"Julia Dpe\", \"Michael Jackson\"],age=[35,35,35,10,5,45], state=[\"CA\",\"CA\",\"CA\",\"CA\",\"CO\",\"CA\"])\r\ncatData = getCategoryData(df_dname, \"age\", [0:10,10:20,20:30])\r\n\r\n# getTreeData(df_dname:: DataFrame, colName:: AbstractString)\r\n# Call this function to create a flatten tree data structure.\r\ndf_dname = DataFrame(name=[\"John Doe\", \"John Doe\",\"MICHAEL Doe\", \"Jacob Doe\", \"Julia Dpe\", \"Michael Jackson\"],age=[35,35,35,10,5,45], state=[\"CA\",\"CA\",\"CA\",\"CA\",\"CO\",\"CA\"])\r\ncatData = getTreeData(df_dname, \"state\")\r\n\r\n# getMaskedData(df_dname:: DataFrame, colNames:: Vector)\r\n# Call this function to create a flatten tree data structure.\r\ndf_dname = DataFrame(name=[\"John Doe\", \"John Doe\",\"MICHAEL Doe\", \"Jacob Doe\", \"Julia Dpe\", \"Michael Jackson\"],age=[35,35,35,10,5,45], state=[\"CA\",\"CA\",\"CA\",\"CA\",\"CO\",\"CA\"])\r\ncatData = getMaskedData(df_dname, \"name\")","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"","category":"page"},{"location":"tutorials/elt/#ETL-Data-warehouse","page":"ELT vs ETL","title":"ETL Data warehouse","text":"","category":"section"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"Lets discuss how to create a Data warehouse like structure while ETL- extracting, loading and transforming data into a Data warehouse structure for faster ad-hoc self service star-schema like reporting.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"We discussed several different ways to extract and load data into the system. To create an ETL Datawarehouse, ","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"A Star schema DIMENSION table is created, where each row must include a SID (Surrogate ID), i.e. a unique identifier available for numerical joins and","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"A Star Schema FACT table is created on primary transaction tables, where, every chartfield/dimention lookup/refernce field, does a look-up on DIMENSION table to get DIMENSION.SID value.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"please refer to LOAD section, METADATA tables structure and look for a field SID.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"after data is extracted from source system, each row is appended with a unique SID value. ","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"For example, -  INSERT INTO table1.sid VALUES sid = (SELECT MAX(SID) FROM JULIADB.METADATA.DATE_BASED_CDC.table1.sid + 1)","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"Everytime, after Data is Extracted and loaded into Target Database, these METADATA tables must be updated.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"","category":"page"},{"location":"tutorials/elt/#ELT-Data-lake","page":"ELT vs ETL","title":"ELT Data lake","text":"","category":"section"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"Lets discuss how to create a Data lake like structure for faster ad-hoc self service star-schema like reporting.","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"To create an ELT Data Lake kind of structure, SID values are optional. Instead, system prefer to perform BULK INSERT or UPDATE. ELT Data Lakes are also easier to create TYPE 2 Dimensions/Facts tables. (Where history is retained).","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"For example - ","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"new rows => INSERT INTO table1 values (SELECT 'active_row=1', table1.* FROM source.table1)","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"update rows => UPDATE table1 SET active_row=0 WHERE rows = <updated rows>","category":"page"},{"location":"tutorials/elt/","page":"ELT vs ETL","title":"ELT vs ETL","text":"update rows => INSERT INTO table1 values (SELECT 'active_row=1', table1.* FROM source.table1)","category":"page"},{"location":"tutorials/erd/#GL-ERD","page":"ERD","title":"GL ERD","text":"","category":"section"},{"location":"tutorials/erd/#General-Ledger-ERD-Entity-Relationship-diagram","page":"ERD","title":"General Ledger ERD- Entity Relationship diagram","text":"","category":"section"},{"location":"tutorials/erd/","page":"ERD","title":"ERD","text":"A typical General Ledger keeps different types summarized Finance informations like company Actuals, Budget, Forecast or Statutory information.","category":"page"},{"location":"tutorials/erd/","page":"ERD","title":"ERD","text":"General Ledger drills down to Journal entries, which again are generated by various accounting processes, which contain $ expenses, revenue, sales, assets or receipt liability details. These sub-ledger entries are generated by various accounting lines of business processes.","category":"page"},{"location":"tutorials/erd/","page":"ERD","title":"ERD","text":"Accounting lines are lowest line of financial details,which further drills down to mobile specific details, For example, an expense, voucher, sales or purchase order may have all details, how and what quantities of commodities or services are procured from which vendors and how much organization owe/liable to pay to vendors. This accounting entries in reality provide necessary information to provide a complete balance General Ledger, which reflect Organization true finance position at any given point of time.","category":"page"},{"location":"tutorials/erd/","page":"ERD","title":"ERD","text":"(Image: GL ERD)","category":"page"},{"location":"introduction/#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Objective:","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"In following chapters, We will work through Data Science, Machine Learning and Deep Learning concepts.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Each chapter will introduce and help us learn a new Data Science AI/ML/DL concept for Finance by actually doing it with real-life examples. These blog's target audience and projects are focused on Small, Medium and Large Enterprise ERP Systems.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"note: ERP systems!\nOracle, PeopleSoft, SAP, Tally, Intuit, QuickBooks etc. I will cover examples from ERP Domains like GL (General Ledger), AP (Accounts Payable), AR (Account Receivables), B2P (Buy to Pay), Expense, Travel & Time, HCM Human Capital Management, CRM etc.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"","category":"page"},{"location":"introduction/#What-is-General-Ledger","page":"Introduction","title":"What is General Ledger","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"GL serves as core of any Financial Management system.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"It's objective is to keep detail and summary accounting information and produce numerous financial reports for your organization.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Often Small businesses see GL as Luxury item and think, it’s only useful for Big organizations. However, Even Big Organization operate in small units and merge into to Corporate Ledger.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"So having a system to read, write and understand your Finance books brings extraordinary benefits to any size of business.","category":"page"},{"location":"introduction/#Technical-Analysis","page":"Introduction","title":"Technical Analysis","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"is the process of forecasting future Organization growth or stock prices based on studying (using advance charting and applying mathematical formulas) past stock prices and trading volume.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Technical analysis strongly believes that at any given point of time, stock price and trading volume reflects it current value and charting accurately captures all factors which can cause upwards or downwards stock prices movement.","category":"page"},{"location":"introduction/#Fundamental-Analysis","page":"Introduction","title":"Fundamental Analysis","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"is the process of forecasting future Organization growth or stock prices based on studying company financial statements like Income Statements, Cash Flow and Balance Sheets.","category":"page"},{"location":"introduction/#Techno-Fundamental-Analysis","page":"Introduction","title":"Techno-Fundamental Analysis","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"In this notebook and all my follow-up GL notebooks, I am proposing 3rd type of analysis.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"With the use of Machine Learning, I want to apply technical analysis /ML algorithms to GL and SUB Ledger (accounting entries) Books.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"warning: Warning\nI make no magical claim that any of my GL AI Notebooks will predict Organization growth or stock prices.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"I strongly believe,","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"A. Using ML Algorithms to predict Growth/Stock Prices or Organization growth is very difficult using past prices/volumes OR GL/Finance data alone.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"B. Using ML Algorithms to predict Growth/Stock Prices or Organization growth is very easy using past prices/volumes + GL/Finance + SUB Ledger (accounting entries) data.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"note: Devil is in details.\nProvided all sub ledgers/accounting entries are available, it is possible to predict Organization growth and lots of Organizations are already doing that.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"However, it is incredibly difficult to do this kind of analysis because Huge ERP systems are difficult to maintain, and it takes a village to read, write and understand Big Financial data in an organization and apply any ML or non-ML logic/algorithm.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"In following chapters, I’ll share very high level AI notebooks to understand and get you started with General Ledger, Data Science operations and Machine Learning.","category":"page"},{"location":"tutorials/plots/#Visualizations,-Buttons,-sliders,-filters,-n-D-plots,-plots-vs-graphs","page":"Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs","title":"Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs","text":"","category":"section"},{"location":"tutorials/plots/","page":"Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs","title":"Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs","text":"Dynamic roll ups","category":"page"},{"location":"tutorials/plots/","page":"Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs","title":"Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs","text":"Invoices by Diversity Vendor groups","category":"page"},{"location":"tutorials/plots/","page":"Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs","title":"Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs","text":"Vendor Ranking","category":"page"},{"location":"tutorials/plots/","page":"Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs","title":"Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs","text":"Product Ranking","category":"page"},{"location":"tutorials/plots/","page":"Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs","title":"Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs","text":"Cost per Invoice","category":"page"},{"location":"tutorials/plots/","page":"Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs","title":"Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs","text":"Operating Expenses trend","category":"page"},{"location":"tutorials/plots/","page":"Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs","title":"Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs","text":"What if scenarios","category":"page"},{"location":"tutorials/plots/","page":"Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs","title":"Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs","text":"Income, Cash-Flow & Balance sheet statements","category":"page"},{"location":"tutorials/plots/","page":"Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs","title":"Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs","text":"Using JULIAGRAPHS for combinational data","category":"page"},{"location":"tutorials/plots/","page":"Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs","title":"Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs","text":"Tree Flattener","category":"page"},{"location":"","page":"Objective","title":"Objective","text":"CurrentModule = GeneralLedger","category":"page"},{"location":"#ML-for-GL-Machine-Learning-for-General-Ledger","page":"Objective","title":"ML for GL - Machine Learning for General Ledger","text":"","category":"section"},{"location":"","page":"Objective","title":"Objective","text":"current release: v0.18\r\nnext planned release: v0.20 Aug 27, 2021.\r\nPlease do NOT download source code until v0.20 release.\r\n\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\r\n!!! source code will available v0.20 Aug 27, 2021 !!!\r\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\r\n\nplanned feature requests:\r\n    v0.20 Bug fixes, enhance ELT, ETL Datawarehouse support\r\n    v0.30 real time Visualizations\r\n    v0.30 real time null hypothesis\r\n    v0.40 Light Graphs/Network science analysis\r\n    v0.60 Blockchain distributed ledger\r\n    v0.70 bug fixes\r\n    v1.00 final stable release","category":"page"},{"location":"#Objective","page":"Objective","title":"Objective","text":"","category":"section"},{"location":"","page":"Objective","title":"Objective","text":"GeneralLedger.jl provide a complete Data Science Framework for Finance Data Analytics.","category":"page"},{"location":"","page":"Objective","title":"Objective","text":"Scope of this package includes General Ledger, Sub-Ledgers, Accounting Analytics & Data Science operations using (Image: JuliaLang) language. GeneralLedger.jl supports analytics using structured data from ERP systems like Oracle, PeopleSoft, SAP, Tally, Intuit, QuickBooks etc.","category":"page"},{"location":"","page":"Objective","title":"Objective","text":"Finance General Ledger sits at core of ERP systems and supporting sub-ledger/accounting entrijes/details are necessary to accurately predict/analyze complete General Ledger functionalities.","category":"page"},{"location":"","page":"Objective","title":"Objective","text":"note -> all sub-ledger/domain specific account will be covered in their own domains like Procure2Pay.jl, TaxAnalytics.jl","category":"page"},{"location":"","page":"Objective","title":"Objective","text":"note: GeneralLedger.jl\nThis package supports all Finance analytical computations for a complete BuytoPay life cycle operation from big ERP systems like Oracle, PeopleSoft, SAP, Tally, Intuit, QuickBooks etc.I will cover examples from ERP Domains like GL (General Ledger), AP (Accounts Payable), AR (Account Receivables), B2P (Buy to Pay), Expense, Travel & Time, HCM Human Capital Management, CRM etc.Requestions -> Orders -> Procurement -> Inventory cycle counting -> Match Exceptions -> Receivables -> Accounts Payables/Billing/Liability -> GL Accounting -> General Ledger book keeping.Future work : - All sub-ledger/domain specific account will be covered in their own domains like AccountsPayables.jl, AccountsReceivables.jl, Procurement.jl etc.","category":"page"},{"location":"","page":"Objective","title":"Objective","text":"","category":"page"},{"location":"","page":"Objective","title":"Objective","text":"This project is accepting funding/sponsorship proposals.","category":"page"},{"location":"","page":"Objective","title":"Objective","text":"(Image: GitHub) (Image: YouTube) (Image: Twitter) (Image: LinkedIn) (Image: Medium)","category":"page"},{"location":"","page":"Objective","title":"Objective","text":"","category":"page"},{"location":"#Table-of-Contents","page":"Objective","title":"Table of Contents","text":"","category":"section"},{"location":"","page":"Objective","title":"Objective","text":"","category":"page"},{"location":"#Index","page":"Objective","title":"Index","text":"","category":"section"},{"location":"","page":"Objective","title":"Objective","text":"","category":"page"}]
}
