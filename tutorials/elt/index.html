<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>ELT vs ETL · GeneralLedger.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="GeneralLedger.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">GeneralLedger.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Objective</a></li><li><a class="tocitem" href="../../introduction/">Introduction</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../aboutgl/">About GL</a></li><li><a class="tocitem" href="../glprocesses/">GL Processes</a></li><li><a class="tocitem" href="../erd/">ERD</a></li><li><a class="tocitem" href="../installation/">Installing Julia</a></li><li class="is-active"><a class="tocitem" href>ELT vs ETL</a><ul class="internal"><li><a class="tocitem" href="#Extract"><span>Extract</span></a></li><li><a class="tocitem" href="#web_crawl"><span>Web crawl &amp; Web Scraping</span></a></li><li><a class="tocitem" href="#Load"><span>Load</span></a></li><li><a class="tocitem" href="#Transform"><span>Transform</span></a></li><li><a class="tocitem" href="#ETL-Data-warehouse"><span>ETL Data warehouse</span></a></li><li><a class="tocitem" href="#ELT-Data-lake"><span>ELT Data lake</span></a></li></ul></li><li><a class="tocitem" href="../selfservice/">Self-Service Data Analytic</a></li><li><a class="tocitem" href="../plots/">Visualizations, Buttons, sliders, filters, n-D plots, plots vs graphs</a></li><li><a class="tocitem" href="../analytic/">p-value, null hypothesis and real time analytic</a></li><li><a class="tocitem" href="../timeseries/">Time Series, Impact analysis</a></li><li><a class="tocitem" href="../mlforgl/">ML for GL</a></li><li><a class="tocitem" href="../nlp/">NLP for GL</a></li><li><a class="tocitem" href="../graph/">Graph Theory / Network Science</a></li></ul></li><li><a class="tocitem" href="../../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>ELT vs ETL</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>ELT vs ETL</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/AmitXShukla/GeneralLedger.jl/blob/master/docs/src/tutorials/elt.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="ELT-vs-ETL.jl"><a class="docs-heading-anchor" href="#ELT-vs-ETL.jl">ELT vs ETL.jl</a><a id="ELT-vs-ETL.jl-1"></a><a class="docs-heading-anchor-permalink" href="#ELT-vs-ETL.jl" title="Permalink"></a></h1><p>ETL Data Warehouse vs ELT Data Lake debate, is like vim vs emacs, linux vs windows never ending discussions.</p><p>It means different things and may represent different concepts, but end of the day leads to one conclusion.</p><p><em>Data is a mineral, if you handle it with care and delicacy, polish and move it to a fine safe enclosure, it will age as fine gold.</em> </p><font color=brown><b> Amit Shukla</b></font>
<br><p>In this lesson, we will discuss different strategies to Extract, Transform, Load data from different sources to different enclosures. You will find examples to address different type of extract, data pull strategies with code.</p><p><strong>Why this package?</strong> There are a dozen ETL/ELT and Data warehouse/ Data lake solutions available in the market today. All of them are extremely capable of extraction, load and transforming almost any type of data structure like structured, un-structured, binary, BLOB, sound, image or simple text in large quantities.</p><p><code>This package neither challenges or aims to build anything different.</code> Instead, this package will use existing RDBMS, DataLakes, or Document databases available in the market.</p><p>This package should be seen as providing a DataType environment, where we can first understand and define subject data structure, then do ELT operations on it. This is what I meant earlier by saying handle with care and delicacy.</p><p><code>Inheriting behavior is much more important than being able to inherit structure.</code></p><p>Just to give an example, Normally, we ingest all vendor tables/transactions into a Data warehouse or Data lake or any self-service environment, and then let SMEs run meaningful analytics on it. instead, Lets first define a Vendor DataType and then build ELT or ETL operations on it. This simple concept will age your data to fine gold and SME will be able to do self-service analytics with worrying too much learning data structure and entity relationships.</p><p>Another example is,  Instead of loading all your accounting data into RDBMS tables, developers take time to pre-define an accounting Data Structure such as JOURNALS, LEDGER, ACCOUNTINGLINES, CHARTFIELDs and HIERARCHY data types, then ELT data into these Data Structures and push it to the reporting database. This will lead to a much powerful driverless self-service live reporting/ predictive analytics environment.</p><p>In the following sections, we will discuss few ETL &amp; ELT strategies.</p><hr/><h2 id="Extract"><a class="docs-heading-anchor" href="#Extract">Extract</a><a id="Extract-1"></a><a class="docs-heading-anchor-permalink" href="#Extract" title="Permalink"></a></h2><p>Data Extraction from a known source is easy, tough part is, automating to fetch data on pre-defined schedules. Further, most difficult task is to identify deltas on every single data row during extract execution and pull/push only changed datasets.</p><p><strong>Stage or not to stage:</strong> keeping an original copy of data into a local/hadoop directory or storing the first original copy in RDBMS tables brings extra benefit to your Analytics. You will always be able to go back in time and restore from originals, however, it also brings unmanageable clutter, junk and storage costs.</p><p>Before trying to read data from source, you must think, how would you want to use it in near future.</p><p>You can store the original copy as-is to a directory or RDBMS table. This works well, when you are dealing with txt, image files. Storage is cheaper than computing.</p><p>for example</p><ul><li>consider storing a copy of the <em>APPL SEC Balance sheet filing PDF</em> from the internet rather than building NLP AI to read certain dollar amounts or quantities from a PDF.</li></ul><p>Your AI scripts will bill more for compute hours than storing a few extra KBs.</p><p>on the other hand, reading 5 lines from 5000 pages PDF, doesn&#39;t justify the need to store the entire document. Instead, use a web crawler, good OCR or text reader AI-bot to fetch data that is meaningful to you.</p><ul><li>while reading data from a RDBMS, consider using a <em>where last<em>update</em>date &gt; last<em>run</em>date</em> to fetch only deltas.</li></ul><p><code>storing &lt;last_run_date&gt; will be discussed in LOAD section later.</code></p><p>Let&#39;s look into few example used to extract different type of data.</p><h4 id="add-GeneralLedger.jl-package"><a class="docs-heading-anchor" href="#add-GeneralLedger.jl-package">add GeneralLedger.jl package</a><a id="add-GeneralLedger.jl-package-1"></a><a class="docs-heading-anchor-permalink" href="#add-GeneralLedger.jl-package" title="Permalink"></a></h4><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; # first, add GeneralLedger.jl package to your environment
       using Pkg</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; Pkg.add(url=&quot;https://github.com/AmitXShukla/GeneralLedger.jl&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">    Updating git-repo `https://github.com/AmitXShukla/GeneralLedger.jl`
    Updating registry at `C:\Users\L569915\.julia\registries\General`
    Updating git-repo `https://github.com/JuliaRegistries/General.git`
ERROR: package `GeneralLedger [640f5719]` has same name or UUID as the active project</code></pre><h4 id="file-download"><a class="docs-heading-anchor" href="#file-download">file download</a><a id="file-download-1"></a><a class="docs-heading-anchor-permalink" href="#file-download" title="Permalink"></a></h4><p><strong>download a simple file from a website, FTP location</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; # let&#39;s download Apple INC Q2 2021 SEC Filing document
       # downloading from website
       # download(url::AbstractString, [path::AbstractString = tempname()]) -&gt; path
       using GeneralLedger</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; fl = getFile(&quot;https://s2.q4cdn.com/470004039/files/doc_financials/2021/q2/FY21-Q2-Consolidated-Financial-Statements.pdf&quot;, &quot;FY21-Q2-Consolidated-Financial-Statements.pdf&quot;);</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; filesize(fl)</code><code class="nohighlight hljs ansi" style="display:block;">881446</code></pre><p><strong>download using curl/wget</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; # let&#39;s download Apple INC Q2 2021 SEC Filing document
       # downloading using curl/wget
       # wrap system commands (curl or wget) inside backticks
       
       downloadFileCommand = `curl https://s2.q4cdn.com/470004039/files/doc_financials/2021/q2/FY21-Q2-Consolidated-Financial-Statements.pdf --output apple_q2-21-10Q.pdf`</code><code class="nohighlight hljs ansi" style="display:block;">`curl https://s2.q4cdn.com/470004039/files/doc_financials/2021/q2/FY21-Q2-Consolidated-Financial-Statements.pdf --output apple_q2-21-10Q.pdf`</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; run(downloadFileCommand)</code><code class="nohighlight hljs ansi" style="display:block;">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0 35  860k   35  303k    0     0   303k      0  0:00:02 --:--:--  0:00:02  922k100  860k  100  860k    0     0   860k      0  0:00:01 --:--:--  0:00:01 2295k
Process(`curl https://s2.q4cdn.com/470004039/files/doc_financials/2021/q2/FY21-Q2-Consolidated-Financial-Statements.pdf --output apple_q2-21-10Q.pdf`, ProcessExited(0))</code></pre><h4 id="auto_data_pull"><a class="docs-heading-anchor" href="#auto_data_pull">automating data pull</a><a id="auto_data_pull-1"></a><a class="docs-heading-anchor-permalink" href="#auto_data_pull" title="Permalink"></a></h4><p>In this section, we will build a simple script, which reads input (urls) file, and downloads all files.</p><p><em>to scrap all available links from webpage tinto a local txt file, see <a href="#web_crawl">Web crawl &amp; Web Scraping</a> section below.</em></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; # use this code, to read all links from a txt file
       # and download each file one by one
       using GeneralLedger</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; getPullFiles(&quot;c:\\amit.la\\file_name.txt&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">&quot;Download complete&quot;</code></pre><h4 id="scheduling-automated-data-pull"><a class="docs-heading-anchor" href="#scheduling-automated-data-pull">scheduling automated data pull</a><a id="scheduling-automated-data-pull-1"></a><a class="docs-heading-anchor-permalink" href="#scheduling-automated-data-pull" title="Permalink"></a></h4><p>In this section, we will learn different options to automate data pull scripts to run on recurring schedule.</p><p>First and preferred option is, user can setup a cron job on Linux or powershell script on windows.</p><pre><code class="nohighlight hljs"># setup a Linux cron job
crontab -e
# minute hour day-of-month month day-of-week command
0 10 * * * Julia autopull.jl</code></pre><p>and if you must do this in Julia, second option is to use native Julia Lang sleep, timer or scheduler functions.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; # code credit - discourse.julialang.org thread
       result = nothing</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; done = false</code><code class="nohighlight hljs ansi" style="display:block;">false</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; while !done
           try
               result = # invoke function that may fail
               done = true
           catch e
               sleep(86400)  # sleep for 1 day(=86400 seconds) before restarting
            end
       end</code><code class="nohighlight hljs ansi" style="display:block;"></code></pre><h4 id="RDBMS,-HIVE"><a class="docs-heading-anchor" href="#RDBMS,-HIVE">RDBMS, HIVE</a><a id="RDBMS,-HIVE-1"></a><a class="docs-heading-anchor-permalink" href="#RDBMS,-HIVE" title="Permalink"></a></h4><p>connecting to Oracle, MY SQL or MS SQL Server</p><p>In this section, below are few examples showing, how to connect to RDBMS SQL databases using ODBC.jl package.</p><p>Please see, user can directly use ODBC.jl package instead of GeneralLedger.jl wrapper functions as shown below. GeneralLedger.jl created this wrapper functions just to enforce and implement standard community guidelines and best practices.</p><p>For example     - It&#39;s not a good idea to pass Database credentials to functions directly, instead, credentials should be kept in separate environment file.     - Similarily, keeping SQLs in xls/txt file is better than using variable to hold SQLs.</p><p>First create a txt file to hold database credentials and make sure DSN are already created in computing environment.</p><p><code>environment.txt</code></p><pre><code class="nohighlight hljs">user=username
pwd=password
dsn=userdsnname
hive=hdinsightstr
port=portnumber</code></pre><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; using GeneralLedger</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; getDSNs()</code><code class="nohighlight hljs ansi" style="display:block;">&quot;available DSNs on your machine.&quot;</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; getDrivers()</code><code class="nohighlight hljs ansi" style="display:block;">&quot;available Drivers on your machine.&quot;</code></pre><p>Next create txt file(s) to hold database SQLs.</p><p><code>sqls.txt</code></p><pre><code class="nohighlight hljs">createTable1=INSERT INTO table1 (column1) SELECT table2.column1 FROM table2 WHERE table2.column1 &gt; 100;
readTable1=SELECT * FROM table1;
updateTable1=UPDATE table SET column1 = value1, column2 = value2, ... WHERE condition;
upsertTable1=BEDIN tran IF EXISTS (SELECT * FROM table1 WITH (updlock,serializable) WHERE key = @key) BEGIN UDPATE table1 SET ... WHERE key = @key END ELSE BEGIN INSERT INTO table1 (key, ...) VALUES (@key, ...) END COMMIT TRAN
softDeleteTable1=UPDATE table SET deleted=True, ... WHERE condition;
hardDeleteTable1=delete * from table1 where table1.column1 &gt; 100</code></pre><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; using GeneralLedger, DataFrames</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; conn = getDBConnection(&quot;environment.txt&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">&quot;access db credentials from conn object. conn.user, conn.pwd... &quot;</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; sql = getSQLs(&quot;sqls.txt&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">&quot;access sqls from sq object. sq.createTable1, sq.upsertTable1 ... &quot;</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; df = runSQL(conn, sql.readTable1) |&gt; DataFrame</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: type String has no field readTable1</code></pre><p>when you are done with SQLs, don&#39;t forget to close DB connection.</p><h4 id="close-DB-Connections"><a class="docs-heading-anchor" href="#close-DB-Connections">close DB Connections</a><a id="close-DB-Connections-1"></a><a class="docs-heading-anchor-permalink" href="#close-DB-Connections" title="Permalink"></a></h4><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; using GeneralLedger</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; setCloseConnection()</code><code class="nohighlight hljs ansi" style="display:block;">&quot;DB Connection is closed now.&quot;</code></pre><p><em>using ODBC to insert data into RDBMS may be very slow operation, see below LOAD section for other methods/strategies to load bulk data.</em></p><h4 id="JSON"><a class="docs-heading-anchor" href="#JSON">JSON</a><a id="JSON-1"></a><a class="docs-heading-anchor-permalink" href="#JSON" title="Permalink"></a></h4><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; # use this code, to download BITCOIN market price into a dataframe
       # and download data in csv format
       using GeneralLedger</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; df = getJSONintoDataFrame(&quot;https://api.coindesk.com/v1/bpi/currentprice.json&quot;, &quot;downloads/web&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">&quot;Download complete&quot;</code></pre><h4 id="XML"><a class="docs-heading-anchor" href="#XML">XML</a><a id="XML-1"></a><a class="docs-heading-anchor-permalink" href="#XML" title="Permalink"></a></h4><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; # use this code, to download XML into a dataframe
       # and download data in csv format
       using GeneralLedger</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; df = getXMLintoDataFrame(&quot;https://www.clinicaltrials.gov/ct2/results/rss.xml?rcv_d=14&amp;lup_d=&amp;sel_rss=new14&amp;cond=Coronavirus&amp;count=10000&quot;, &quot;downloads/web&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">&quot;Download complete&quot;</code></pre><hr/><h2 id="web_crawl"><a class="docs-heading-anchor" href="#web_crawl">Web crawl &amp; Web Scraping</a><a id="web_crawl-1"></a><a class="docs-heading-anchor-permalink" href="#web_crawl" title="Permalink"></a></h2><p>We just looked at examples, how to download file(s) from website or FTP locations. However in some case, you may not know how many files are available for download.</p><p>In this example below, we will use this GeneralLedger.jl function, which crawl through Apple INC SEC Filing web page (or any webpage), reads HTML and identify all PDF/XLSX or CSV files downloadable links.</p><p>We will store these links into csv file and this file can be used in <a href="#auto_data_pull">automating data pull</a>, to automatically download all files at once.</p><p><strong>start a webdriver session</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; # you must have a valid webdriver session running on your machine
       # download a valid chromedriver version on your machine from this link
       # https://chromedriver.chromium.org/downloads (may vary)
       # after you download, open a terminal window &amp; browe to directory
       # where chromedrive.exe is location and run
       # chromedriver.exe --url-base=/wd/hub
       # above command will start a chrome webdriver session on port 9515
       
       wdrvCommand = `chromedriver.exe --url-base=/wd/hub`</code><code class="nohighlight hljs ansi" style="display:block;">`chromedriver.exe --url-base=/wd/hub`</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # if you see an error below, that&#39;s because I didn&#39;t provide correct path
       # to find chromedriver.exe file
       run(wdrvCommand)</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: IOError: could not spawn `chromedriver.exe --url-base=/wd/hub`: no such file or directory (ENOENT)</code></pre><p><strong>web crawl &amp; web scraping</strong></p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; # Call this function to crawl through a web page and download all file links
       # first parameter is webpage url, next parameter is list of all file extensions
       # where user wish to download followed by output directory path
       using GeneralLedger</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; getWebLinks(&quot;https://investor.apple.com/investor-relations/default.aspx#tabs_content--2021&quot;, [&quot;pdf&quot;,&quot;csv&quot;,&quot;xlsx&quot;,&quot;xls&quot;], &quot;downloads/web&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">&quot;HTTPS://INVESTOR.APPLE.COM/INVESTOR_RELATIONS/DEFAULT.ASPX_TABS_CONTENT__2021&quot;</code></pre><p>GeneralLedger <code>getWebLinks</code> function fetches and store these links into csv file, which is used in <a href="#auto_data_pull">automating data pull</a>, to automatically download all files at once.</p><hr/><h2 id="Load"><a class="docs-heading-anchor" href="#Load">Load</a><a id="Load-1"></a><a class="docs-heading-anchor-permalink" href="#Load" title="Permalink"></a></h2><p>Now once data is identified, we will need a storage system, typically a database, data warehouse or data lake to keep data. Before loading into a Target system, let&#39;s work on our load strategy.</p><p>Think of these scenarios you will be dealing after data is loaded.</p><ul><li>simple excel files first row will be used as RDBMS table names. Often, RDBMS will change column headers and this will be a challenge to map with original excel files each time a newer file is downloaded.</li><li>you dont want to fetch the same file if it already exists in the local/hadoop directory.</li><li>in case of RDBMS, you may want to mark each record with CRUD date (when a row was first created, updated and read. You may never want to hard delete a row, and just do a soft delete instead to hide from the user&#39;s view).</li></ul><p>using ODBC to load BULK data could be very slow operations, instead Cloud data upload strategies are highly recommended to move data.</p><p>For Example, using Oracle, Google or Azure cloud storage systems could be easier option to load huge datasets into RDBMs.</p><p><a href="https://cloud.google.com/sql/docs/mysql/import-export/importing">Google Cloud SQL upload strategy</a></p><p><a href="https://docs.oracle.com/en/database/oracle/machine-learning/oml4py/1/mlpug/push-data-to-database.html#GUID-C50C0D37-C057-43CE-BE4B-750E52865E2C">Oracle Cloud upload strategy</a></p><p><code>TODO: will update this section to show case how to use Julia to upload Big Data into cloud databases.</code></p><p>First, we will create few METADAT tables to store LOAD information.</p><p>Ideally, These METADATA tables should be stores in Target system database, however, just to showcase, data LOAD Strategy, in this case, We will use <code>JULIADB</code> to capture TABLES LOAD METADATA information.</p><h4 id="meta_data_table"><a class="docs-heading-anchor" href="#meta_data_table">METADATA tables</a><a id="meta_data_table-1"></a><a class="docs-heading-anchor-permalink" href="#meta_data_table" title="Permalink"></a></h4><p><code>METADATA.LOADTIME</code> This table is used to store information related to each table METADATA. Everytime, after Data is Extracted and loaded into Target Database, these METADATA tables must be updated.</p><pre><code class="nohighlight hljs">name=tablename
sor=source_system_name
author=source_system_userid
updateAt=lastupddttm</code></pre><p><code>METADATA.DATE_BASED_CDC</code> create One METADATA file per table. This table is used to store information related to each table read from source through a date based <code>CDC (Change data capture)</code> logic. and next time, same date is used to pull incremental data from source system.</p><p>For example, -  <code>SELECT * FROM sourceDB.table1 WHERE sourceDB.table1.updateDttm &gt; JULIADB.METADATA.DATE_BASED_CDC.table1.incrementDt</code></p><p>Everytime, after Data is Extracted and loaded into Target Database, these METADATA tables must be updated.</p><pre><code class="nohighlight hljs">name=tablename
sor=source_system_name
author=source_system_userid
updateAt=lastupddttm
incrementDt=max_updateDt_at_source # Leave blank in case of KEYs based CDC
sid=maxDourrogateID # unique numerical identifier per row, used in ETL Datawarehouse.
                    # Leave blank is case of ELT Data lake</code></pre><p><code>METADATA.KEYS_BASED_CDC</code> create One METADATA file per table. This table is used to store information related to each table read from source through a date based <code>CDC (Change data capture)</code> logic. and next time, same date is used to pull incremental data from source system.</p><p>For example, -  <code>SELECT [key_columns] FROM sourceDB.table1 &lt;MATCH&gt; JULIADB.METADATA.DATE_BASED_CDC.table1.key1..2..3 =&gt; INSERT / UPDATE / UPSERT</code></p><p>Everytime, after Data is Extracted and loaded into Target Database, these METADATA tables must be updated.</p><pre><code class="nohighlight hljs">key1=primarykey
key2=primarykey
key3=primarykey
author=source_system_userid
createAt=currentdttm # do not update this, in case of an update
updateAt=currentdttm
sid=maxDourrogateID # unique numerical identifier per row, used in ETL Datawarehouse.
                    # Leave blank is case of ELT Data lake</code></pre><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; using GeneralLedger</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; getDSNs()</code><code class="nohighlight hljs ansi" style="display:block;">&quot;available DSNs on your machine.&quot;</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; getDrivers()</code><code class="nohighlight hljs ansi" style="display:block;">&quot;available Drivers on your machine.&quot;</code></pre><hr/><h2 id="Transform"><a class="docs-heading-anchor" href="#Transform">Transform</a><a id="Transform-1"></a><a class="docs-heading-anchor-permalink" href="#Transform" title="Permalink"></a></h2><p>What seems hardest, is the easiest part to deal with. Once a correct dataset is read and loaded into the system. There are several transformation techniques and tools available.</p><p>In ELT like environments, Transformation is mostly done on Analytical tool, like Microsoft Power BI, Tableau, Oracle Analytics are extremely powerful and provide out of the box transformation techniques.</p><p>However, here are some useful scripts, which can be run on local environment for data cleansing. These GeneralLedger.jl data cleansing/tranformation funcitons are extremely powerful when dealing with extreme large Big data sets.</p><ul><li>read all xls files from a directory <code>getXLSinDirectory</code></li><li>removing unwanted chars in columns headers or rows <code>setColNames</code></li><li>arrange words (remove unwanted chars, sort and return uppercase) <code>getArrangedWords</code></li><li>FuzzyWuzzy - finds closest match for a given string in data frame column <code>getFuzzyWuzzy</code></li><li>removing missing, NA, Tokens <code>getTokens</code>, <code>setRemoveTokens</code></li><li>removing words <code>setRemoveText</code></li><li>replacing text <code>setReplaceText</code></li><li>identifying duplicates <code>getDuplicateRows</code></li><li>identifying key columns in dataset <code>getKeyColumns</code></li><li>removing duplicates <code>setRemDuplicateRows</code></li><li>categorizing data <code>getCategoryData</code></li><li>creating Hierarchy, Tree like dimensional structure <code>getTreeData</code></li><li>creating synthetic/masked reversible data (produces two files, one with masked data and original with masked data) <code>getMaskedData</code></li></ul><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; using GeneralLedger, DataFrames</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # getXLSinDirectory
       # read all xls files from a directory
       getXLSinDirectory(&quot;.&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: .\FY21-Q2-Consolidated-Financial-Statements.pdf is not a valid XLSX file.</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # setColNames
       # Call this function to remove not-compatible SQL columns chars
       setColNames(&quot;Amit Sh-ukla # \$&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">&quot;AMIT_SH_UKLA____&quot;</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # getArrangedWords
       # Call this function to remove duplicates, unwanted symbols and return uppercase unique values
       wd = getArrangedWords(&quot;Amit ; Shukla SHUKLA Shukle , . AmIT Amit # Shuklam Amit ,&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">4-element Vector{String}:
 &quot;AMIT&quot;
 &quot;SHUKLA&quot;
 &quot;SHUKLAM&quot;
 &quot;SHUKLE&quot;</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # getFuzzyWuzzy
       # Call this function to find closest match for a given string in data frame column lookup
       # First parameter is the search string, second is the DataFrame followed by columnname in DataFrame which needs to be searched
       df_dname = DataFrame(name=[&quot;John Doe&quot;, &quot;Jen Doe&quot;,&quot;MICHAEL Doe&quot;, &quot;Jacob Doe&quot;, &quot;Julia Dpe&quot;, &quot;Michael Jackson&quot;],age=[35,26,35,10,5,45])</code><code class="nohighlight hljs ansi" style="display:block;">6×2 DataFrame
 Row │ name             age
     │ String           Int64
─────┼────────────────────────
   1 │ John Doe            35
   2 │ Jen Doe             26
   3 │ MICHAEL Doe         35
   4 │ Jacob Doe           10
   5 │ Julia Dpe            5
   6 │ Michael Jackson     45</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; wd = getFuzzyWuzzy(&quot;Mike Jackson&quot;, df_dname, &quot;name&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: UndefVarError: RatcliffObershelp not defined</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # getTokens
       # Call this function to extract tokens from string (example - extract urls)
       # First parameter is the complete string text, next parameter is list of words to be removed.
       wd = getTokens(&quot;https://yahoo.com is the Yahoo website url&quot;, url)</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: UndefVarError: url not defined</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # setRemoveTokens
       # Call this function to remove tokens
       wd = setRemoveTokens(&quot;Amit Shukla Shkla Los Angel Angeles&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">&quot;Amit Shukla Los Angeles&quot;</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # setRemoveText
       # Call this function to find and remove word in text string
       # First parameter is the complete string text, next parameter is list of words to be removed.
       wd = setRemoveText(&quot;Amit Shukla Shkla Los Angel Angeles&quot;, [&quot;Shkla&quot;, &quot;Angel&quot;])</code><code class="nohighlight hljs ansi" style="display:block;">&quot;Amit Shukla Los Angeles&quot;</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # setReplaceText
       # Call this function to find and replace word in text string
       # First parameter is the term to be replaced, next is the term replaced with followed by text string where text is searched and replaced.
       wd = setReplaceText(&quot;Shkla&quot;,&quot;Shukla &quot;,&quot;Amit Shkla Los Angeles&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">&quot;Shukla &quot;</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # getDuplicateRows
       # Call this function to find duplicates in a data frame column based on columnnames (key columns)
       df_dname = DataFrame(name=[&quot;John Doe&quot;, &quot;John Doe&quot;,&quot;MICHAEL Doe&quot;, &quot;Jacob Doe&quot;, &quot;Julia Dpe&quot;, &quot;Michael Jackson&quot;],age=[35,35,35,10,5,45], state=[&quot;CA&quot;,&quot;CA&quot;,&quot;CA&quot;,&quot;CA&quot;,&quot;CO&quot;,&quot;CA&quot;])</code><code class="nohighlight hljs ansi" style="display:block;">6×3 DataFrame
 Row │ name             age    state
     │ String           Int64  String
─────┼────────────────────────────────
   1 │ John Doe            35  CA
   2 │ John Doe            35  CA
   3 │ MICHAEL Doe         35  CA
   4 │ Jacob Doe           10  CA
   5 │ Julia Dpe            5  CO
   6 │ Michael Jackson     45  CA</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; dup = getDuplicateRows(df_dname, [&quot;name&quot;,&quot;age&quot;])</code><code class="nohighlight hljs ansi" style="display:block;">(1, 2)</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # getKeyColumns
       # Call this function to find key columns in a data frame
       df_dname = DataFrame(name=[&quot;John Doe&quot;, &quot;John Doe&quot;,&quot;MICHAEL Doe&quot;, &quot;Jacob Doe&quot;, &quot;Julia Dpe&quot;, &quot;Michael Jackson&quot;],age=[35,35,35,10,5,45], state=[&quot;CA&quot;,&quot;CA&quot;,&quot;CA&quot;,&quot;CA&quot;,&quot;CO&quot;,&quot;CA&quot;])</code><code class="nohighlight hljs ansi" style="display:block;">6×3 DataFrame
 Row │ name             age    state
     │ String           Int64  String
─────┼────────────────────────────────
   1 │ John Doe            35  CA
   2 │ John Doe            35  CA
   3 │ MICHAEL Doe         35  CA
   4 │ Jacob Doe           10  CA
   5 │ Julia Dpe            5  CO
   6 │ Michael Jackson     45  CA</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; kcols = getKeyColumns(df_dname)</code><code class="nohighlight hljs ansi" style="display:block;">(1, 2, 3)</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # setRemDuplicateRows
       # Call this function to find &amp; delete duplicates in a data frame column based on columnnames (key columns)
       df_dname = DataFrame(name=[&quot;John Doe&quot;, &quot;John Doe&quot;,&quot;MICHAEL Doe&quot;, &quot;Jacob Doe&quot;, &quot;Julia Dpe&quot;, &quot;Michael Jackson&quot;],age=[35,35,35,10,5,45], state=[&quot;CA&quot;,&quot;CA&quot;,&quot;CA&quot;,&quot;CA&quot;,&quot;CO&quot;,&quot;CA&quot;])</code><code class="nohighlight hljs ansi" style="display:block;">6×3 DataFrame
 Row │ name             age    state
     │ String           Int64  String
─────┼────────────────────────────────
   1 │ John Doe            35  CA
   2 │ John Doe            35  CA
   3 │ MICHAEL Doe         35  CA
   4 │ Jacob Doe           10  CA
   5 │ Julia Dpe            5  CO
   6 │ Michael Jackson     45  CA</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; dup = setRemDuplicateRows(df_dname, [&quot;name&quot;,&quot;age&quot;])</code><code class="nohighlight hljs ansi" style="display:block;">&quot;dataframe after removing duplicates&quot;</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # getCategoryData
       # Call this function to create a new column on DataFrame which provide a category based on ranges provided.
       df_dname = DataFrame(name=[&quot;John Doe&quot;, &quot;John Doe&quot;,&quot;MICHAEL Doe&quot;, &quot;Jacob Doe&quot;, &quot;Julia Dpe&quot;, &quot;Michael Jackson&quot;],age=[35,35,35,10,5,45], state=[&quot;CA&quot;,&quot;CA&quot;,&quot;CA&quot;,&quot;CA&quot;,&quot;CO&quot;,&quot;CA&quot;])</code><code class="nohighlight hljs ansi" style="display:block;">6×3 DataFrame
 Row │ name             age    state
     │ String           Int64  String
─────┼────────────────────────────────
   1 │ John Doe            35  CA
   2 │ John Doe            35  CA
   3 │ MICHAEL Doe         35  CA
   4 │ Jacob Doe           10  CA
   5 │ Julia Dpe            5  CO
   6 │ Michael Jackson     45  CA</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; catData = getCategoryData(df_dname, &quot;age&quot;, [0:10,10:20,20:30])</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: MethodError: no method matching getCategoryData(::DataFrames.DataFrame, ::String, ::Vector{UnitRange{Int64}})
Closest candidates are:
  getCategoryData(::Any, ::Any) at C:\amit.la\WIP\GeneralLedger.jl\src\ELTs\elt.jl:356</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # getTreeData(df_dname:: DataFrame, colName:: AbstractString)
       # Call this function to create a flatten tree data structure.
       df_dname = DataFrame(name=[&quot;John Doe&quot;, &quot;John Doe&quot;,&quot;MICHAEL Doe&quot;, &quot;Jacob Doe&quot;, &quot;Julia Dpe&quot;, &quot;Michael Jackson&quot;],age=[35,35,35,10,5,45], state=[&quot;CA&quot;,&quot;CA&quot;,&quot;CA&quot;,&quot;CA&quot;,&quot;CO&quot;,&quot;CA&quot;])</code><code class="nohighlight hljs ansi" style="display:block;">6×3 DataFrame
 Row │ name             age    state
     │ String           Int64  String
─────┼────────────────────────────────
   1 │ John Doe            35  CA
   2 │ John Doe            35  CA
   3 │ MICHAEL Doe         35  CA
   4 │ Jacob Doe           10  CA
   5 │ Julia Dpe            5  CO
   6 │ Michael Jackson     45  CA</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; catData = getTreeData(df_dname, &quot;state&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">&quot;original dataframe with levels, level 1 has two nodes CA, CO which contains name field as children.&quot;</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # getMaskedData(df_dname:: DataFrame, colNames:: Vector)
       # Call this function to create a flatten tree data structure.
       df_dname = DataFrame(name=[&quot;John Doe&quot;, &quot;John Doe&quot;,&quot;MICHAEL Doe&quot;, &quot;Jacob Doe&quot;, &quot;Julia Dpe&quot;, &quot;Michael Jackson&quot;],age=[35,35,35,10,5,45], state=[&quot;CA&quot;,&quot;CA&quot;,&quot;CA&quot;,&quot;CA&quot;,&quot;CO&quot;,&quot;CA&quot;])</code><code class="nohighlight hljs ansi" style="display:block;">6×3 DataFrame
 Row │ name             age    state
     │ String           Int64  String
─────┼────────────────────────────────
   1 │ John Doe            35  CA
   2 │ John Doe            35  CA
   3 │ MICHAEL Doe         35  CA
   4 │ Jacob Doe           10  CA
   5 │ Julia Dpe            5  CO
   6 │ Michael Jackson     45  CA</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; catData = getMaskedData(df_dname, &quot;name&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">&quot;one dataframe is with name field encrypted, other contains original and masked values both.&quot;</code></pre><hr/><h2 id="ETL-Data-warehouse"><a class="docs-heading-anchor" href="#ETL-Data-warehouse">ETL Data warehouse</a><a id="ETL-Data-warehouse-1"></a><a class="docs-heading-anchor-permalink" href="#ETL-Data-warehouse" title="Permalink"></a></h2><p>Lets discuss how to create a Data warehouse like structure while ETL- extracting, loading and transforming data into a Data warehouse structure for faster ad-hoc self service star-schema like reporting.</p><p>We discussed several different ways to extract and load data into the system. To create an ETL Datawarehouse, </p><p>A Star schema DIMENSION table is created, where each row must include a SID (Surrogate ID), i.e. a unique identifier available for numerical joins and</p><p>A Star Schema FACT table is created on primary transaction tables, where, every chartfield/dimention lookup/refernce field, does a look-up on DIMENSION table to get DIMENSION.SID value.</p><p>please refer to <a href="#meta_data_table">LOAD</a> section, METADATA tables structure and look for a field SID.</p><p>after data is extracted from source system, each row is appended with a unique SID value. </p><p>For example, -  <code>INSERT INTO table1.sid VALUES sid = (SELECT MAX(SID) FROM JULIADB.METADATA.DATE_BASED_CDC.table1.sid + 1)</code></p><p>Everytime, after Data is Extracted and loaded into Target Database, these METADATA tables must be updated.</p><hr/><h2 id="ELT-Data-lake"><a class="docs-heading-anchor" href="#ELT-Data-lake">ELT Data lake</a><a id="ELT-Data-lake-1"></a><a class="docs-heading-anchor-permalink" href="#ELT-Data-lake" title="Permalink"></a></h2><p>Lets discuss how to create a Data lake like structure for faster ad-hoc self service star-schema like reporting.</p><p>To create an ELT Data Lake kind of structure, SID values are optional. Instead, system prefer to perform BULK INSERT or UPDATE. ELT Data Lakes are also easier to create TYPE 2 Dimensions/Facts tables. (Where history is retained).</p><p>For example - </p><p><code>new rows =&gt; INSERT INTO table1 values (SELECT &#39;active_row=1&#39;, table1.* FROM source.table1)</code></p><p><code>update rows =&gt; UPDATE table1 SET active_row=0 WHERE rows = &lt;updated rows&gt;</code></p><p><code>update rows =&gt; INSERT INTO table1 values (SELECT &#39;active_row=1&#39;, table1.* FROM source.table1)</code></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../installation/">« Installing Julia</a><a class="docs-footer-nextpage" href="../selfservice/">Self-Service Data Analytic »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.4 on <span class="colophon-date" title="Thursday 29 July 2021 21:56">Thursday 29 July 2021</span>. Using Julia version 1.6.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
