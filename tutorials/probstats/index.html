<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Probability &amp; Statistics · GeneralLedger.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="GeneralLedger.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">GeneralLedger.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Objective</a></li><li><a class="tocitem" href="../../introduction/">Introduction</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../aboutgl/">About GL</a></li><li><a class="tocitem" href="../glprocesses/">GL Processes</a></li><li><a class="tocitem" href="../erd/">ERD</a></li><li><a class="tocitem" href="../installation/">Installing Julia</a></li><li><a class="tocitem" href="../selfservice/">Self-Service Data Analytics</a></li><li><a class="tocitem" href="../plots/">Visualizations</a></li><li><input class="collapse-toggle" id="menuitem-3-7" type="checkbox" checked/><label class="tocitem" for="menuitem-3-7"><span class="docs-label">ML4GL</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../mlforgl/">Machine Learning</a></li><li><a class="tocitem" href="../finmath/">Finance Mathematics</a></li><li class="is-active"><a class="tocitem" href>Probability &amp; Statistics</a><ul class="internal"><li><a class="tocitem" href="#Probability-and-Statistical-Distributions"><span>Probability and Statistical Distributions</span></a></li><li><a class="tocitem" href="#Probability"><span>Probability</span></a></li><li><a class="tocitem" href="#Sample-space"><span>Sample space</span></a></li><li><a class="tocitem" href="#Probability-axioms"><span>Probability axioms</span></a></li><li><a class="tocitem" href="#Probability-consequences"><span>Probability consequences</span></a></li><li><a class="tocitem" href="#Probability-Distributions-Functions-(PDFs)"><span>Probability Distributions Functions (PDFs)</span></a></li><li><a class="tocitem" href="#Probability-Mass-Function-(PMF)"><span>Probability Mass Function (PMF)</span></a></li><li><a class="tocitem" href="#Probability-Density-Function-(PDF)"><span>Probability Density Function (PDF)</span></a></li><li><a class="tocitem" href="#Cumulative-Density-Function-(CDF)"><span>Cumulative Density Function (CDF)</span></a></li><li><a class="tocitem" href="#CLT-Central-limit-Theorem"><span>CLT - Central limit Theorem</span></a></li><li><a class="tocitem" href="#Distributions"><span>Distributions</span></a></li><li><a class="tocitem" href="#Normal-Gaussian,-Binomial,-Poisson,-Exponential"><span>Normal Gaussian, Binomial, Poisson, Exponential</span></a></li><li><a class="tocitem" href="#Mean,-median,-mode,-average,-weighted-average,-EWA"><span>Mean, median, mode, average, weighted average, EWA</span></a></li><li><a class="tocitem" href="#p-value,-quantile,-quartile"><span>p value, quantile, quartile</span></a></li><li><a class="tocitem" href="#standard-deviation,-Correlation,-covariance"><span>standard deviation, Correlation, covariance</span></a></li><li><a class="tocitem" href="#moments,-entropy,-skewness,-kurtosis,-entropy"><span>moments, entropy, skewness, kurtosis, entropy</span></a></li><li><a class="tocitem" href="#regression-is-another-blog-with-optimization"><span>regression is another blog with optimization</span></a></li></ul></li><li><a class="tocitem" href="../hypothesis/">p-value, null hypothesis and real time analytic</a></li><li><a class="tocitem" href="../optimization/">Optimization</a></li><li><a class="tocitem" href="../derivatives/">Derivative &amp; Gradients</a></li><li><a class="tocitem" href="../dl/">Deep Learning</a></li></ul></li><li><a class="tocitem" href="../nlp/">NLP for GL</a></li><li><a class="tocitem" href="../transformers/">Transformers</a></li><li><a class="tocitem" href="../graph/">Graph Theory / Network Science</a></li><li><a class="tocitem" href="../chatgpt/">Open AI ChatGPT</a></li><li><a class="tocitem" href="../elt/">ELT vs ETL</a></li></ul></li><li><a class="tocitem" href="../../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li><a class="is-disabled">ML4GL</a></li><li class="is-active"><a href>Probability &amp; Statistics</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Probability &amp; Statistics</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/AmitXShukla/GeneralLedger.jl/blob/master/docs/src/tutorials/probstats.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Probability-and-Statistics"><a class="docs-heading-anchor" href="#Probability-and-Statistics">Probability &amp; Statistics</a><a id="Probability-and-Statistics-1"></a><a class="docs-heading-anchor-permalink" href="#Probability-and-Statistics" title="Permalink"></a></h1><hr/><p>In this chapter, we will examine the <strong>basics of probability and statistical distributions</strong>, and how they relate to our financial data.</p><ul><li><a href="#Probability-and-Statistical-Distributions">Probability and Statistical Distributions</a><ul><li><a href="#Probability">Probability</a></li><li><a href="#Sample-space">Sample space</a></li><li><a href="#Probability-axioms">Probability axioms</a></li><li><a href="#Probability-consequences">Probability consequences</a></li></ul></li><li><a href="#Probability-Distributions-Functions-(PDFs)">Probability Distributions Functions (PDFs)</a><ul><li><a href="#Probability-Mass-Function-(PMF)">Probability Mass Function (PMF)</a></li><li><a href="#Probability-Density-Function-(PDF)">Probability Density Function (PDF)</a></li><li><a href="#Cumulative-Density-Function-(CDF)">Cumulative Density Function (CDF)</a></li><li><a href="#Probability-Distributions-Functions-(PDFs)">Probability Distributions Functions (PDFs)</a></li></ul></li><li><a href="#CLT-Central-limit-Theorem">CLT - Central limit Theorem</a></li><li><a href="#Distributions">Distributions</a><ul><li><a href="#Normal-Gaussian,-Binomial,-Poisson,-Exponential">Normal Gaussian, Binomial, Poisson, Exponential</a></li><li><a href="#Mean,-median,-mode,-average,-weighted-average,-EWA">Mean, median, mode, average, weighted average, EWA</a></li><li><a href="#p-value,-quantile,-quartile">p value, quantile, quartile</a></li><li><a href="#standard-deviation,-Correlation,-covariance">standard deviation, Correlation, covariance</a></li><li><a href="#moments,-entropy,-skewness,-kurtosis,-entropy">moments, entropy, skewness, kurtosis, entropy</a></li></ul></li></ul><h2 id="Probability-and-Statistical-Distributions"><a class="docs-heading-anchor" href="#Probability-and-Statistical-Distributions">Probability and Statistical Distributions</a><a id="Probability-and-Statistical-Distributions-1"></a><a class="docs-heading-anchor-permalink" href="#Probability-and-Statistical-Distributions" title="Permalink"></a></h2><hr/><p><strong>how do you explain what a probability distribution in statistics is?</strong></p><p>In simple terms, we use a single value to represent a group of data. This value is called the measure of central tendency and it describes what is typical or average in the data. Common measures of central tendency include the mean, median, and mode.</p><p>Probability and distributions aid in comprehending general patterns within data during statistical analysis.</p><p>For example, given a set of 100k different Mutual Funds or Stock prices estimated growth is, we want to have a general idea of about how each group of Mutual Fund or stock prices is performing in over all market conditions.</p><div class="admonition is-info"><header class="admonition-header">what&#39;s the point of learning statistics for Finance ML</header><div class="admonition-body"><p>If you are wondering, why we even care of learning probability, statistics, algebra and calculus functions for the sake of Finance Analytics. It&#39;s because building AI, is all about using mathematics to find statistical association to rationally predict outcome of an event given a set of inputs, than casual reasoning.</p><p>As we progress, we will see, how learning statistical associations and using calculus for automation in small steps, lead to performing statistical tasks, automate predictive analytics, which are fast improved fact based statistical association rather than casual reasoning, and often outperforms human intuitive analytics.</p></div></div><h2 id="Probability"><a class="docs-heading-anchor" href="#Probability">Probability</a><a id="Probability-1"></a><a class="docs-heading-anchor-permalink" href="#Probability" title="Permalink"></a></h2><hr/><p>A probability event is defined as set of outcomes of an experiment. In simpler words, Probability is likelihood of occurrence of an event.</p><p>As an example, What’s the probability of the fair coin landing on Heads?</p><p>Calculating statistical probability mathematically helps us answer these type of questions.</p><p class="math-container">\[    f = Number of favorable Outcomes \\
    T = Total number of outcomes \\
    P(X = Head) = \frac{f}{T} \\
    P(X = Head) = \frac{P(H)}{P(H)+P(T)} \\
    P(X = Head) = \frac{1}{1+1} \\
    P(X = Head) = 0.5\]</p><p>Similarly, calculating mathematical probabilities may help us answer more complex questions like, given our Finance data, We may want to use Probability or likelihood of best possible return from given amount invested in certain investment group/category.</p><table><tr><th style="text-align: right">Category</th><th style="text-align: right">ROI (%)</th></tr><tr><td style="text-align: right">A</td><td style="text-align: right">3</td></tr><tr><td style="text-align: right">B</td><td style="text-align: right">5</td></tr><tr><td style="text-align: right">C</td><td style="text-align: right">4</td></tr><tr><td style="text-align: right">D</td><td style="text-align: right">2</td></tr></table><pre><code class="language-julia hljs">ROI_by_InvestmentGroup</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">                        ROT by Investment group          
              ┌                                        ┐ 
            A ┤■■■■■■■■■■■■■■■■■■■■■■ 3                  
   Category B ┤■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■ 5   
            C ┤■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■ 4          
            D ┤■■■■■■■■■■■■■■■ 2                         
              └                                        ┘ 
                                ROI (%)                  </code></pre><p>for example, above data/figure shows, Category B has maximum ROI. However, assuming, one Mutual Fund belongs to only one category, probability of getting maximum ROI on a given fund is <code>0.25</code>.</p><p class="math-container">\[    f = Number of favorable Outcomes \\
    T = Total number of outcomes \\
    P(X = maxROI) = \frac{f}{T} \\
    P(X = maxROI) = \frac{P(C)}{P(A)+P(B)+P(C)+P(D)} \\
    P(X = maxROI) = \frac{1}{1+1+1+1} \\
    P(X = maxROI) = 0.25\]</p><h2 id="Sample-space"><a class="docs-heading-anchor" href="#Sample-space">Sample space</a><a id="Sample-space-1"></a><a class="docs-heading-anchor-permalink" href="#Sample-space" title="Permalink"></a></h2><hr/><p>All set of possible set of outcomes of an experiment is the sample space.</p><p>let&#39;s assume, given there are 4 possible directions (<span>$North$</span>, <span>$South$</span>, <span>$East$</span>, <span>$West$</span>).</p><ul><li>Probability of person walking in North Direction is <code>1/4</code>. Given Sample space (<span>$North$</span>, <span>$South$</span>, <span>$East$</span>, <span>$West$</span>).</li></ul><p class="math-container">\[    P(X = N) = \frac{f}{T} \\
    P(X = N) = \frac{P(N)}{P(N)+P(S)+P(E)+P(W)} \\
    P(X = N) = \frac{1}{1+1+1+1} \\
    P(X = N) = 0.25\]</p><ul><li>Probability of person walking in <span>$North$</span>(ish) Direction is <code>3/8</code>. Given Sample space is <code>(N, NE, NW, S, SE, SW, E, W)</code>.</li></ul><p class="math-container">\[    P(X = N(ish)) = \frac{f}{T} \\
    P(X = N(ish)) = \frac{P(N)+P(NE)+P(NW)}{P(N)+P(S)+P(E)+P(W)+P(NE)+P(NW)+P(SW)+P(SE)} \\
    P(X = N(ish)) = \frac{1+1+1}{1+1+1+1+1+1+1+1} \\
    P(X = N(ish)) = \frac{3}{8}\]</p><p><code>Determining statistical probability accurately depends on context and sample space.</code></p><p><img src="../prob.png" alt/></p><p><strong>Application:</strong> As seen in above examples, We can apply similar concepts in our given finance data set. For example, given outcome ROI, which group one Mutual Fund belongs to, and further, what is the likelihood of maximum profit given stocks in included in Fund.</p><p>Keep in mind, in above examples, Sample space and possible outcomes are in finite in numbers and hence are considered as discrete probability functions. Later sections, we will see continuous probability distributions which often have infinite outcomes.</p><h2 id="Probability-axioms"><a class="docs-heading-anchor" href="#Probability-axioms">Probability axioms</a><a id="Probability-axioms-1"></a><a class="docs-heading-anchor-permalink" href="#Probability-axioms" title="Permalink"></a></h2><hr/><ul><li>The probability of occurrence of any event lies between 0 and 1.   <span>$P(X) \in (0,1)$</span></li><li>The sum of all the probabilities of outcomes should be equal to 1.   <span>$P(\Omega) = 1$</span></li><li>For mutually exclusive events, sum of probabilities is equal to sum of individual event probabilities.   <span>$P\left(\bigcup _{i=1}^{\infty }E_{i}\right)=\sum _{i=1}^{\infty }P(E_{i}).$</span></li></ul><h2 id="Probability-consequences"><a class="docs-heading-anchor" href="#Probability-consequences">Probability consequences</a><a id="Probability-consequences-1"></a><a class="docs-heading-anchor-permalink" href="#Probability-consequences" title="Permalink"></a></h2><hr/><ul><li>The probability of occurrence of any event lies between 0 and 1.   <span>$P(X) \in (0,1)$</span></li><li>The sum of all the probabilities of outcomes should be equal to 1.   <span>$P(\Omega) = 1$</span></li><li>For mutually exclusive events, sum of probabilities is equal to sum of individual event probabilities.   <span>$P\left(\bigcup _{i=1}^{\infty }E_{i}\right)=\sum _{i=1}^{\infty }P(E_{i})$</span></li></ul><h2 id="Probability-Distributions-Functions-(PDFs)"><a class="docs-heading-anchor" href="#Probability-Distributions-Functions-(PDFs)">Probability Distributions Functions (PDFs)</a><a id="Probability-Distributions-Functions-(PDFs)-1"></a><a class="docs-heading-anchor-permalink" href="#Probability-Distributions-Functions-(PDFs)" title="Permalink"></a></h2><hr/><p>Probability Distribution functions (referred as PDFs), not to be confused with Probability density function (PDF), is the mathematical function that gives the probabilities of occurrence of different possible outcomes for an experiment. It is a mathematical description of a random phenomenon in terms of its sample space and the probabilities of events (subsets of the sample space).</p><p class="math-container">\[    PDFs \Rrightarrow
    \left[\begin{array}{c}
        Discrete \Leftrightarrow PMF \\
        Continuous \Leftrightarrow PDF
    \end{array}\right]
    \Rrightarrow 
    CDF\]</p><div class="admonition is-info"><header class="admonition-header">what&#39;s the point of learning PDFs</header><div class="admonition-body"><p>just to keep reader and objective of this tutorials aligned, the whole reason, we are learning about probability distributions is, it helps us visualize data in terms of &quot;central or distributed&quot; tendency and/or estimating an event or point of interest in terms of maximum likelihood of occurrence.</p></div></div><h2 id="Probability-Mass-Function-(PMF)"><a class="docs-heading-anchor" href="#Probability-Mass-Function-(PMF)">Probability Mass Function (PMF)</a><a id="Probability-Mass-Function-(PMF)-1"></a><a class="docs-heading-anchor-permalink" href="#Probability-Mass-Function-(PMF)" title="Permalink"></a></h2><h2 id="Probability-Density-Function-(PDF)"><a class="docs-heading-anchor" href="#Probability-Density-Function-(PDF)">Probability Density Function (PDF)</a><a id="Probability-Density-Function-(PDF)-1"></a><a class="docs-heading-anchor-permalink" href="#Probability-Density-Function-(PDF)" title="Permalink"></a></h2><h2 id="Cumulative-Density-Function-(CDF)"><a class="docs-heading-anchor" href="#Cumulative-Density-Function-(CDF)">Cumulative Density Function (CDF)</a><a id="Cumulative-Density-Function-(CDF)-1"></a><a class="docs-heading-anchor-permalink" href="#Cumulative-Density-Function-(CDF)" title="Permalink"></a></h2><p>Probability density/mass functions (pdf) and their logarithm (logpdf)</p><hr/><p>So far, we have seen examples of simple, compound interest certificate deposit types. Now let&#39;s dig in deeper and move onto another type of deposit types, i.e. Mutual Funds, stocks, options equity etc.</p><p>Before we jump on to more advance Machine learning training, model and predictive analytics, let&#39;s spend time on statistical analysis and visualizing probability distributions of data first.</p><p>Above analysis is the key to machine learning and predictive analytics. Understanding below statistical concepts lay strong foundations for ML/DL modeling later on.</p><p>In this section, we will focus on performing Univariate analysis on Mutual fund data, as you can see in below data sample, that rate type, compound interest type does&#39;t impact MF performance, in this dataset, outcome depends on only one variable, &quot;Group Type&quot;.</p><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>Once we get a hang of analyzing data on one variable, later we will introduce more variables like MF Type, contents, market type etc. Then in later section, we will train our neural network on multiple inputs.</p></div></div><p>In this example below, we will work on datasets from GeneralLedger.jl package in following steps.</p><ul><li>first draw one million data samples from GeneralLedger.jl package</li><li>groupby data by deposit type</li><li>filter data to include only Mutual Funds</li></ul><pre><code class="language-julia hljs">using GeneralLedger, DataFrames, Statistics;
sampleSize = 1000000;
df = GeneralLedger.getSampleDepositsData(sampleSize);
subset!(df, :deposit =&gt; x -&gt; contains.(x, &quot;MF&quot;));

dfG = groupby(df, [:rate]);
combine(dfG, nrow, proprow, groupindices, :Total =&gt; mean =&gt; :mean, :Total =&gt; std =&gt; :std);
# dfA = subset(df, :rate =&gt; x -&gt; isequal.(x, &quot;Group A&quot;));

show(first(dfA,5)) # show first 5 rows

describe(dfA.Total) # describe stats

dfC = combine(dfG, nrow, proprow, groupindices, :Total =&gt; mean =&gt; :mean, :Total =&gt; std =&gt; :std);
show(first(dfC,5)) # show first 5 rows</code></pre><table><tr><th style="text-align: right">deposit</th><th style="text-align: right">amount</th><th style="text-align: right">ROI</th><th style="text-align: right">time</th><th style="text-align: right">rate</th><th style="text-align: right">compound</th><th style="text-align: right">Interest</th><th style="text-align: right">Total</th></tr><tr><td style="text-align: right">MF-1</td><td style="text-align: right">100000.0</td><td style="text-align: right">0.0</td><td style="text-align: right">60.0</td><td style="text-align: right">Group A</td><td style="text-align: right">1.0</td><td style="text-align: right">97000.0</td><td style="text-align: right">197000.0</td></tr><tr><td style="text-align: right">MF-2</td><td style="text-align: right">100000.0</td><td style="text-align: right">0.0</td><td style="text-align: right">60.0</td><td style="text-align: right">Group D</td><td style="text-align: right">1.0</td><td style="text-align: right">-39000.0</td><td style="text-align: right">61000.0</td></tr><tr><td style="text-align: right">MF-3</td><td style="text-align: right">100000.0</td><td style="text-align: right">0.0</td><td style="text-align: right">60.0</td><td style="text-align: right">Group D</td><td style="text-align: right">1.0</td><td style="text-align: right">-27000.0</td><td style="text-align: right">73000.0</td></tr><tr><td style="text-align: right">MF-4</td><td style="text-align: right">100000.0</td><td style="text-align: right">0.0</td><td style="text-align: right">60.0</td><td style="text-align: right">Group D</td><td style="text-align: right">1.0</td><td style="text-align: right">-29000.0</td><td style="text-align: right">71000.0</td></tr><tr><td style="text-align: right">MF-5</td><td style="text-align: right">100000.0</td><td style="text-align: right">0.0</td><td style="text-align: right">60.0</td><td style="text-align: right">Group B</td><td style="text-align: right">1.0</td><td style="text-align: right">19000.0</td><td style="text-align: right">119000.0</td></tr><tr><td style="text-align: right">MF-6</td><td style="text-align: right">100000.0</td><td style="text-align: right">0.0</td><td style="text-align: right">60.0</td><td style="text-align: right">Group B</td><td style="text-align: right">1.0</td><td style="text-align: right">19000.0</td><td style="text-align: right">119000.0</td></tr><tr><td style="text-align: right">MF-7</td><td style="text-align: right">100000.0</td><td style="text-align: right">0.0</td><td style="text-align: right">60.0</td><td style="text-align: right">Group D</td><td style="text-align: right">1.0</td><td style="text-align: right">-31000.0</td><td style="text-align: right">69000.0</td></tr><tr><td style="text-align: right">MF-8</td><td style="text-align: right">100000.0</td><td style="text-align: right">0.0</td><td style="text-align: right">60.0</td><td style="text-align: right">Group D</td><td style="text-align: right">1.0</td><td style="text-align: right">-35000.0</td><td style="text-align: right">65000.0</td></tr><tr><td style="text-align: right">MF-9</td><td style="text-align: right">100000.0</td><td style="text-align: right">0.0</td><td style="text-align: right">60.0</td><td style="text-align: right">Group A</td><td style="text-align: right">1.0</td><td style="text-align: right">43000.0</td><td style="text-align: right">143000.0</td></tr><tr><td style="text-align: right">MF-10</td><td style="text-align: right">100000.0</td><td style="text-align: right">0.0</td><td style="text-align: right">60.0</td><td style="text-align: right">Group A</td><td style="text-align: right">1.0</td><td style="text-align: right">55000.0</td><td style="text-align: right">155000.0</td></tr></table><ul><li>as you can see, above data set is divided in 4 groups and each group has different type of outcomes.</li><li>we will assume, these groups have further characteristics, which lead them to produce outcome in certain ranges.</li><li>for example, Group A invests in certain types of equities which performed better or worse than others.</li><li>however, with in a group, outcome are somewhat consistent (like in certain range).</li><li>abnormal distribution with in one certain group is another topic for detail analysis.</li><li>in later sections, we will only focus on doing analytics at one group level.</li><li>let&#39;s visualize groups altogether.</li></ul><p><img src="../group_data.png" alt="Distributions Graphs"/></p><p>as you can see in above graphs, Group A has largest population and has greatest means as well. Meaning, given 100k investment, overall ROI can be anywhere between 120-180k. Standard deviation in results are very high as range 120-180 on 100k original amount is very wide.</p><p>Similarly, Group B, Group C follow Group A in ROI. Group D has second largest population but is worse performing, and most of the time, ROI is less then 100k, which is under performing and losing investment anywhere from 40-50k.</p><h2 id="CLT-Central-limit-Theorem"><a class="docs-heading-anchor" href="#CLT-Central-limit-Theorem">CLT - Central limit Theorem</a><a id="CLT-Central-limit-Theorem-1"></a><a class="docs-heading-anchor-permalink" href="#CLT-Central-limit-Theorem" title="Permalink"></a></h2><hr/><p>`as per wikipedia&#39; In probability theory, the central limit theorem (CLT) establishes that, in many situations, when independent random variables are summed up, their properly normalized sum tends toward a normal distribution even if the original variables themselves are not normally distributed.</p><p>The theorem is a key concept in probability theory because it implies that probabilistic and statistical methods that work for normal distributions can be applicable to many problems involving other types of distributions.</p><h2 id="Distributions"><a class="docs-heading-anchor" href="#Distributions">Distributions</a><a id="Distributions-1"></a><a class="docs-heading-anchor-permalink" href="#Distributions" title="Permalink"></a></h2><hr/><h2 id="Normal-Gaussian,-Binomial,-Poisson,-Exponential"><a class="docs-heading-anchor" href="#Normal-Gaussian,-Binomial,-Poisson,-Exponential">Normal Gaussian, Binomial, Poisson, Exponential</a><a id="Normal-Gaussian,-Binomial,-Poisson,-Exponential-1"></a><a class="docs-heading-anchor-permalink" href="#Normal-Gaussian,-Binomial,-Poisson,-Exponential" title="Permalink"></a></h2><hr/><h2 id="Mean,-median,-mode,-average,-weighted-average,-EWA"><a class="docs-heading-anchor" href="#Mean,-median,-mode,-average,-weighted-average,-EWA">Mean, median, mode, average, weighted average, EWA</a><a id="Mean,-median,-mode,-average,-weighted-average,-EWA-1"></a><a class="docs-heading-anchor-permalink" href="#Mean,-median,-mode,-average,-weighted-average,-EWA" title="Permalink"></a></h2><h2 id="p-value,-quantile,-quartile"><a class="docs-heading-anchor" href="#p-value,-quantile,-quartile">p value, quantile, quartile</a><a id="p-value,-quantile,-quartile-1"></a><a class="docs-heading-anchor-permalink" href="#p-value,-quantile,-quartile" title="Permalink"></a></h2><h2 id="standard-deviation,-Correlation,-covariance"><a class="docs-heading-anchor" href="#standard-deviation,-Correlation,-covariance">standard deviation, Correlation, covariance</a><a id="standard-deviation,-Correlation,-covariance-1"></a><a class="docs-heading-anchor-permalink" href="#standard-deviation,-Correlation,-covariance" title="Permalink"></a></h2><h2 id="moments,-entropy,-skewness,-kurtosis,-entropy"><a class="docs-heading-anchor" href="#moments,-entropy,-skewness,-kurtosis,-entropy">moments, entropy, skewness, kurtosis, entropy</a><a id="moments,-entropy,-skewness,-kurtosis,-entropy-1"></a><a class="docs-heading-anchor-permalink" href="#moments,-entropy,-skewness,-kurtosis,-entropy" title="Permalink"></a></h2><p>notes</p><h2 id="regression-is-another-blog-with-optimization"><a class="docs-heading-anchor" href="#regression-is-another-blog-with-optimization">regression is another blog with optimization</a><a id="regression-is-another-blog-with-optimization-1"></a><a class="docs-heading-anchor-permalink" href="#regression-is-another-blog-with-optimization" title="Permalink"></a></h2><p>linear regression, what is linear regression, GLM etc. refer to statistics data science math topics</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../finmath/">« Finance Mathematics</a><a class="docs-footer-nextpage" href="../hypothesis/">p-value, null hypothesis and real time analytic »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Wednesday 25 January 2023 17:09">Wednesday 25 January 2023</span>. Using Julia version 1.9.0-beta2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
